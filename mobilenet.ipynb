{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcXHC1c5VYA0",
        "outputId": "96cd962a-4ccf-4b30-acf6-5d5d5e5eb98c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.13.0+cu116\n",
            "Torchvision Version:  0.14.0+cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pthflops\n",
            "  Downloading pthflops-0.4.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from pthflops) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->pthflops) (4.4.0)\n",
            "Installing collected packages: pthflops\n",
            "Successfully installed pthflops-0.4.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from thop) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->thop) (4.4.0)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from efficientnet_pytorch) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->efficientnet_pytorch) (4.4.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=f63aba263f8519c5b43687e1eae6c7e7add07601628ce6f956cb2a4498f78ce4\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/b9/90/25a0195cf95fb5533db96f1c77ea3f296b7cc86ae8ae48e3dc\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from torchvision import datasets, models, transforms\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "import time\n",
        "print(\"PyTorch Version: \", torch.__version__)\n",
        "print(\"Torchvision Version: \", torchvision.__version__)\n",
        "!mkdir data\n",
        "data_dir = Path('./data')\n",
        "net_fn = Path('./net')\n",
        "import math\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "from prettytable import PrettyTable\n",
        "!pip install pthflops\n",
        "from pthflops import count_ops\n",
        "import copy\n",
        "!pip install torchinfo\n",
        "import torchinfo\n",
        "!pip install thop\n",
        "from thop import profile\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "!pip install --upgrade efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from scipy.linalg import svd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "WtF6asURVe-V"
      },
      "outputs": [],
      "source": [
        "dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBXsnklfVfA2",
        "outputId": "dd14b581-b05d-4bc9-d0ee-d9eabdae7e58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Number of validation images: 50000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# Mount data directory to google drive\n",
        "\"\"\"\n",
        "Used the comments in code to execute the file, when used with an account \n",
        "that has access to the shared folder of the class, the code will automatically run\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('./drive')\n",
        "\n",
        "# Copy to local for faster extraction\n",
        "!cp drive/Shareddrives/penn-ese-5390-202230/ILSVRC2012_img_val.tar ./data\n",
        "!cp drive/Shareddrives/penn-ese-5390-202230/ILSVRC2012_devkit_t3.tar.gz ./data\n",
        "!cp drive/Shareddrives/penn-ese-5390-202230/ILSVRC2012_devkit_t12.tar.gz ./data\n",
        "\n",
        "# Create transform to preprocess data\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# # Copy to local for faster extraction\n",
        "# !cp /content/drive/Shareddrives/539/ILSVRC2012_img_val.tar ./data\n",
        "# !cp /content/drive/Shareddrives/539/ILSVRC2012_devkit_t3.tar.gz ./data\n",
        "# !cp /content/drive/Shareddrives/539/ILSVRC2012_devkit_t12.tar.gz ./data\n",
        "\n",
        "# val_transform = transforms.Compose([\n",
        "#     transforms.Resize(224),\n",
        "#     transforms.CenterCrop(224),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "# ])\n",
        "\n",
        "# Create validation dataset\n",
        "val_dataset = datasets.ImageNet('./data', split='val', transform=val_transform)\n",
        "\n",
        "# Create validation dataloader\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, num_workers=4)\n",
        "\n",
        "print(f'Number of validation images: {len(val_dataset)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "oONQEvXJVfEq"
      },
      "outputs": [],
      "source": [
        "def validate_model(model, dataloader, device=\"cpu\", n=None):\n",
        "    model.eval()\n",
        "    running_corrects = 0\n",
        "    total = 0\n",
        "\n",
        "    # Move model to device (CPU or GPU)\n",
        "    # One time to amortize data movement\n",
        "    dev = torch.device(device)\n",
        "    model.to(dev)\n",
        "\n",
        "    # Iterate over data stopping early if n is set\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "        if (n is not None and i >= n):\n",
        "            break\n",
        "        # Send inputs to device\n",
        "        inputs = inputs.to(dev)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        temp = labels.data\n",
        "        if(device==\"cuda\"):\n",
        "          temp = temp.to(device=\"cuda\")\n",
        "\n",
        "\n",
        "        # Gather statistics\n",
        "        running_corrects += torch.sum(predicted == temp)\n",
        "        total += inputs.size()[0]       # get batch size\n",
        "\n",
        "        if i % 200 == 199:\n",
        "            acc = 100 * running_corrects.double() / total\n",
        "            print(f'[{i + 1}] {acc:.4f}%')\n",
        "\n",
        "    epoch_acc = 100 * running_corrects.double() / total\n",
        "\n",
        "    return epoch_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "NLEjQQF3VfG8"
      },
      "outputs": [],
      "source": [
        "def compare_models(model_1, model_2):\n",
        "    # Move models to specified device\n",
        "    model_1 = model_1.to(dev)\n",
        "    model_2 = model_2.to(dev)\n",
        "    \n",
        "    # Initialize counter for number of differences between models\n",
        "    models_differ = 0\n",
        "    \n",
        "    # Iterate over keys and values of state dictionaries in parallel\n",
        "    for key_1, value_1, key_2, value_2 in zip(model_1.state_dict().keys(), model_1.state_dict().values(), model_2.state_dict().keys(), model_2.state_dict().values()):\n",
        "        # If keys are not the same, raise exception\n",
        "        if key_1 != key_2:\n",
        "            raise Exception('Mismatch in keys of model state dictionaries')\n",
        "        # If values are not equal, check if key contains 'weight' and increment counter\n",
        "        if not torch.equal(value_1, value_2):\n",
        "            if 'weight' not in key_1:\n",
        "                models_differ += 1\n",
        "                print('Mismatch found at', key_1)\n",
        "    # If counter is 0, print message indicating models match perfectly\n",
        "    if models_differ == 0:\n",
        "        print('Models match perfectly! :)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "SMt-Qo2FVovu"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "  \n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])# Initialize table and total parameter count\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters(): # Iterate over model's named parameters\n",
        "        if not parameter.requires_grad: continue # Skip parameters that do not require gradients\n",
        "        params = parameter.numel()# Get number of parameters and add to table and total count\n",
        "        table.add_row([name, params])\n",
        "        total_params+=params\n",
        "    # print(table)\n",
        "    # print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ap7Dx_X3Vozl"
      },
      "outputs": [],
      "source": [
        "def _flops(layer, ip):\n",
        "    input = torch.randn(1, ip, 224, 224) # Generate random input tensor\n",
        "    flops, params = profile(layer, inputs=input) # Calculate FLOPS and number of parameters for the layer\n",
        "    return flops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "HCbu9Jt1Vo13"
      },
      "outputs": [],
      "source": [
        "model_mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "model_mobilenet = model_mobilenet.to(dev)\n",
        "# summary(model_mobilenet, input_size = (3,224,224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMbQ0w0zVo3n",
        "outputId": "c09f9b0a-c8bd-467c-8fda-cd28e6e2da6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===============================================================================================================================================================================\n",
            "Layer (type:depth-idx)                             Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n",
            "===============================================================================================================================================================================\n",
            "MobileNetV2                                        [1, 3, 224, 224]          [1, 1000]                 --                        --                        --\n",
            "├─Sequential: 1-1                                  [1, 3, 224, 224]          [1, 1280, 7, 7]           --                        --                        --\n",
            "│    └─Conv2dNormActivation: 2-1                   [1, 3, 224, 224]          [1, 32, 112, 112]         --                        --                        --\n",
            "│    │    └─Conv2d: 3-1                            [1, 3, 224, 224]          [1, 32, 112, 112]         864                       [3, 3]                    10,838,016\n",
            "│    │    └─BatchNorm2d: 3-2                       [1, 32, 112, 112]         [1, 32, 112, 112]         64                        --                        64\n",
            "│    │    └─ReLU6: 3-3                             [1, 32, 112, 112]         [1, 32, 112, 112]         --                        --                        --\n",
            "│    └─InvertedResidual: 2-2                       [1, 32, 112, 112]         [1, 16, 112, 112]         --                        --                        --\n",
            "│    │    └─Sequential: 3-4                        [1, 32, 112, 112]         [1, 16, 112, 112]         896                       --                        10,035,296\n",
            "│    └─InvertedResidual: 2-3                       [1, 16, 112, 112]         [1, 24, 56, 56]           --                        --                        --\n",
            "│    │    └─Sequential: 3-5                        [1, 16, 112, 112]         [1, 24, 56, 56]           5,136                     --                        29,202,864\n",
            "│    └─InvertedResidual: 2-4                       [1, 24, 56, 56]           [1, 24, 56, 56]           --                        --                        --\n",
            "│    │    └─Sequential: 3-6                        [1, 24, 56, 56]           [1, 24, 56, 56]           8,832                     --                        25,740,912\n",
            "│    └─InvertedResidual: 2-5                       [1, 24, 56, 56]           [1, 32, 28, 28]           --                        --                        --\n",
            "│    │    └─Sequential: 3-7                        [1, 24, 56, 56]           [1, 32, 28, 28]           10,000                    --                        15,467,392\n",
            "│    └─InvertedResidual: 2-6                       [1, 32, 28, 28]           [1, 32, 28, 28]           --                        --                        --\n",
            "│    │    └─Sequential: 3-8                        [1, 32, 28, 28]           [1, 32, 28, 28]           14,848                    --                        10,989,376\n",
            "│    └─InvertedResidual: 2-7                       [1, 32, 28, 28]           [1, 32, 28, 28]           --                        --                        --\n",
            "│    │    └─Sequential: 3-9                        [1, 32, 28, 28]           [1, 32, 28, 28]           14,848                    --                        10,989,376\n",
            "│    └─InvertedResidual: 2-8                       [1, 32, 28, 28]           [1, 64, 14, 14]           --                        --                        --\n",
            "│    │    └─Sequential: 3-10                       [1, 32, 28, 28]           [1, 64, 14, 14]           21,056                    --                        7,564,928\n",
            "│    └─InvertedResidual: 2-9                       [1, 64, 14, 14]           [1, 64, 14, 14]           --                        --                        --\n",
            "│    │    └─Sequential: 3-11                       [1, 64, 14, 14]           [1, 64, 14, 14]           54,272                    --                        10,312,832\n",
            "│    └─InvertedResidual: 2-10                      [1, 64, 14, 14]           [1, 64, 14, 14]           --                        --                        --\n",
            "│    │    └─Sequential: 3-12                       [1, 64, 14, 14]           [1, 64, 14, 14]           54,272                    --                        10,312,832\n",
            "│    └─InvertedResidual: 2-11                      [1, 64, 14, 14]           [1, 64, 14, 14]           --                        --                        --\n",
            "│    │    └─Sequential: 3-13                       [1, 64, 14, 14]           [1, 64, 14, 14]           54,272                    --                        10,312,832\n",
            "│    └─InvertedResidual: 2-12                      [1, 64, 14, 14]           [1, 96, 14, 14]           --                        --                        --\n",
            "│    │    └─Sequential: 3-14                       [1, 64, 14, 14]           [1, 96, 14, 14]           66,624                    --                        12,721,344\n",
            "│    └─InvertedResidual: 2-13                      [1, 96, 14, 14]           [1, 96, 14, 14]           --                        --                        --\n",
            "│    │    └─Sequential: 3-15                       [1, 96, 14, 14]           [1, 96, 14, 14]           118,272                   --                        22,694,592\n",
            "│    └─InvertedResidual: 2-14                      [1, 96, 14, 14]           [1, 96, 14, 14]           --                        --                        --\n",
            "│    │    └─Sequential: 3-16                       [1, 96, 14, 14]           [1, 96, 14, 14]           118,272                   --                        22,694,592\n",
            "│    └─InvertedResidual: 2-15                      [1, 96, 14, 14]           [1, 160, 7, 7]            --                        --                        --\n",
            "│    │    └─Sequential: 3-17                       [1, 96, 14, 14]           [1, 160, 7, 7]            155,264                   --                        15,610,496\n",
            "│    └─InvertedResidual: 2-16                      [1, 160, 7, 7]            [1, 160, 7, 7]            --                        --                        --\n",
            "│    │    └─Sequential: 3-18                       [1, 160, 7, 7]            [1, 160, 7, 7]            320,000                   --                        15,480,320\n",
            "│    └─InvertedResidual: 2-17                      [1, 160, 7, 7]            [1, 160, 7, 7]            --                        --                        --\n",
            "│    │    └─Sequential: 3-19                       [1, 160, 7, 7]            [1, 160, 7, 7]            320,000                   --                        15,480,320\n",
            "│    └─InvertedResidual: 2-18                      [1, 160, 7, 7]            [1, 320, 7, 7]            --                        --                        --\n",
            "│    │    └─Sequential: 3-20                       [1, 160, 7, 7]            [1, 320, 7, 7]            473,920                   --                        23,007,040\n",
            "│    └─Conv2dNormActivation: 2-19                  [1, 320, 7, 7]            [1, 1280, 7, 7]           --                        --                        --\n",
            "│    │    └─Conv2d: 3-21                           [1, 320, 7, 7]            [1, 1280, 7, 7]           409,600                   [1, 1]                    20,070,400\n",
            "│    │    └─BatchNorm2d: 3-22                      [1, 1280, 7, 7]           [1, 1280, 7, 7]           2,560                     --                        2,560\n",
            "│    │    └─ReLU6: 3-23                            [1, 1280, 7, 7]           [1, 1280, 7, 7]           --                        --                        --\n",
            "├─Sequential: 1-2                                  [1, 1280]                 [1, 1000]                 --                        --                        --\n",
            "│    └─Dropout: 2-20                               [1, 1280]                 [1, 1280]                 --                        --                        --\n",
            "│    └─Linear: 2-21                                [1, 1280]                 [1, 1000]                 1,281,000                 --                        1,281,000\n",
            "===============================================================================================================================================================================\n",
            "Total params: 3,504,872\n",
            "Trainable params: 3,504,872\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 300.81\n",
            "===============================================================================================================================================================================\n",
            "Input size (MB): 0.60\n",
            "Forward/backward pass size (MB): 106.86\n",
            "Params size (MB): 14.02\n",
            "Estimated Total Size (MB): 121.48\n",
            "===============================================================================================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(torchinfo.summary(model_mobilenet, (3, 224, 224), batch_dim = 0, col_names = (\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"), verbose = 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpG5NojepSIF"
      },
      "source": [
        "The following code is simulating image scaling for phi values from 0 to 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdjn71e7Vo7Q",
        "outputId": "1e9acb28-daa1-45df-eea5-5e51e8058293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operation              OPS        \n",
            "---------------------  ---------  \n",
            "features_0_0           10838016   \n",
            "features_0_1           802816     \n",
            "features_1_conv_0_0    3612672    \n",
            "features_1_conv_0_1    802816     \n",
            "features_1_conv_1      6422528    \n",
            "features_1_conv_2      401408     \n",
            "features_2_conv_0_0    19267584   \n",
            "features_2_conv_0_1    2408448    \n",
            "features_2_conv_1_0    2709504    \n",
            "features_2_conv_1_1    602112     \n",
            "features_2_conv_2      7225344    \n",
            "features_2_conv_3      150528     \n",
            "features_3_conv_0_0    10838016   \n",
            "features_3_conv_0_1    903168     \n",
            "features_3_conv_1_0    4064256    \n",
            "features_3_conv_1_1    903168     \n",
            "features_3_conv_2      10838016   \n",
            "features_3_conv_3      150528     \n",
            "add                    150528     \n",
            "features_4_conv_0_0    10838016   \n",
            "features_4_conv_0_1    903168     \n",
            "features_4_conv_1_0    1016064    \n",
            "features_4_conv_1_1    225792     \n",
            "features_4_conv_2      3612672    \n",
            "features_4_conv_3      50176      \n",
            "features_5_conv_0_0    4816896    \n",
            "features_5_conv_0_1    301056     \n",
            "features_5_conv_1_0    1354752    \n",
            "features_5_conv_1_1    301056     \n",
            "features_5_conv_2      4816896    \n",
            "features_5_conv_3      50176      \n",
            "add_1                  50176      \n",
            "features_6_conv_0_0    4816896    \n",
            "features_6_conv_0_1    301056     \n",
            "features_6_conv_1_0    1354752    \n",
            "features_6_conv_1_1    301056     \n",
            "features_6_conv_2      4816896    \n",
            "features_6_conv_3      50176      \n",
            "add_2                  50176      \n",
            "features_7_conv_0_0    4816896    \n",
            "features_7_conv_0_1    301056     \n",
            "features_7_conv_1_0    338688     \n",
            "features_7_conv_1_1    75264      \n",
            "features_7_conv_2      2408448    \n",
            "features_7_conv_3      25088      \n",
            "features_8_conv_0_0    4816896    \n",
            "features_8_conv_0_1    150528     \n",
            "features_8_conv_1_0    677376     \n",
            "features_8_conv_1_1    150528     \n",
            "features_8_conv_2      4816896    \n",
            "features_8_conv_3      25088      \n",
            "add_3                  25088      \n",
            "features_9_conv_0_0    4816896    \n",
            "features_9_conv_0_1    150528     \n",
            "features_9_conv_1_0    677376     \n",
            "features_9_conv_1_1    150528     \n",
            "features_9_conv_2      4816896    \n",
            "features_9_conv_3      25088      \n",
            "add_4                  25088      \n",
            "features_10_conv_0_0   4816896    \n",
            "features_10_conv_0_1   150528     \n",
            "features_10_conv_1_0   677376     \n",
            "features_10_conv_1_1   150528     \n",
            "features_10_conv_2     4816896    \n",
            "features_10_conv_3     25088      \n",
            "add_5                  25088      \n",
            "features_11_conv_0_0   4816896    \n",
            "features_11_conv_0_1   150528     \n",
            "features_11_conv_1_0   677376     \n",
            "features_11_conv_1_1   150528     \n",
            "features_11_conv_2     7225344    \n",
            "features_11_conv_3     37632      \n",
            "features_12_conv_0_0   10838016   \n",
            "features_12_conv_0_1   225792     \n",
            "features_12_conv_1_0   1016064    \n",
            "features_12_conv_1_1   225792     \n",
            "features_12_conv_2     10838016   \n",
            "features_12_conv_3     37632      \n",
            "add_6                  37632      \n",
            "features_13_conv_0_0   10838016   \n",
            "features_13_conv_0_1   225792     \n",
            "features_13_conv_1_0   1016064    \n",
            "features_13_conv_1_1   225792     \n",
            "features_13_conv_2     10838016   \n",
            "features_13_conv_3     37632      \n",
            "add_7                  37632      \n",
            "features_14_conv_0_0   10838016   \n",
            "features_14_conv_0_1   225792     \n",
            "features_14_conv_1_0   254016     \n",
            "features_14_conv_1_1   56448      \n",
            "features_14_conv_2     4515840    \n",
            "features_14_conv_3     15680      \n",
            "features_15_conv_0_0   7526400    \n",
            "features_15_conv_0_1   94080      \n",
            "features_15_conv_1_0   423360     \n",
            "features_15_conv_1_1   94080      \n",
            "features_15_conv_2     7526400    \n",
            "features_15_conv_3     15680      \n",
            "add_8                  15680      \n",
            "features_16_conv_0_0   7526400    \n",
            "features_16_conv_0_1   94080      \n",
            "features_16_conv_1_0   423360     \n",
            "features_16_conv_1_1   94080      \n",
            "features_16_conv_2     7526400    \n",
            "features_16_conv_3     15680      \n",
            "add_9                  15680      \n",
            "features_17_conv_0_0   7526400    \n",
            "features_17_conv_0_1   94080      \n",
            "features_17_conv_1_0   423360     \n",
            "features_17_conv_1_1   94080      \n",
            "features_17_conv_2     15052800   \n",
            "features_17_conv_3     31360      \n",
            "features_18_0          20070400   \n",
            "features_18_1          125440     \n",
            "classifier_1           1281000    \n",
            "--------------------   --------   \n",
            "Input size: (1, 3, 224, 224)\n",
            "314,564,264 FLOPs or approx. 0.31 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "phi = 0\n",
        "\"\"\"\n",
        "ip = torch.rand(1,3,224,224).to(dev)\n",
        "temp = count_ops(model_mobilenet, ip) # Count the number of FLOPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EAEAetuVfI7",
        "outputId": "90736afe-fe3b-488e-d7a5-204855501b98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operation              OPS        \n",
            "---------------------  ---------  \n",
            "features_0_0           21842784   \n",
            "features_0_1           1617984    \n",
            "features_1_conv_0_0    7280928    \n",
            "features_1_conv_0_1    1617984    \n",
            "features_1_conv_1      12943872   \n",
            "features_1_conv_2      808992     \n",
            "features_2_conv_0_0    38831616   \n",
            "features_2_conv_0_1    4853952    \n",
            "features_2_conv_1_0    5529600    \n",
            "features_2_conv_1_1    1228800    \n",
            "features_2_conv_2      14745600   \n",
            "features_2_conv_3      307200     \n",
            "features_3_conv_0_0    22118400   \n",
            "features_3_conv_0_1    1843200    \n",
            "features_3_conv_1_0    8294400    \n",
            "features_3_conv_1_1    1843200    \n",
            "features_3_conv_2      22118400   \n",
            "features_3_conv_3      307200     \n",
            "add                    307200     \n",
            "features_4_conv_0_0    22118400   \n",
            "features_4_conv_0_1    1843200    \n",
            "features_4_conv_1_0    2073600    \n",
            "features_4_conv_1_1    460800     \n",
            "features_4_conv_2      7372800    \n",
            "features_4_conv_3      102400     \n",
            "features_5_conv_0_0    9830400    \n",
            "features_5_conv_0_1    614400     \n",
            "features_5_conv_1_0    2764800    \n",
            "features_5_conv_1_1    614400     \n",
            "features_5_conv_2      9830400    \n",
            "features_5_conv_3      102400     \n",
            "add_1                  102400     \n",
            "features_6_conv_0_0    9830400    \n",
            "features_6_conv_0_1    614400     \n",
            "features_6_conv_1_0    2764800    \n",
            "features_6_conv_1_1    614400     \n",
            "features_6_conv_2      9830400    \n",
            "features_6_conv_3      102400     \n",
            "add_2                  102400     \n",
            "features_7_conv_0_0    9830400    \n",
            "features_7_conv_0_1    614400     \n",
            "features_7_conv_1_0    691200     \n",
            "features_7_conv_1_1    153600     \n",
            "features_7_conv_2      4915200    \n",
            "features_7_conv_3      51200      \n",
            "features_8_conv_0_0    9830400    \n",
            "features_8_conv_0_1    307200     \n",
            "features_8_conv_1_0    1382400    \n",
            "features_8_conv_1_1    307200     \n",
            "features_8_conv_2      9830400    \n",
            "features_8_conv_3      51200      \n",
            "add_3                  51200      \n",
            "features_9_conv_0_0    9830400    \n",
            "features_9_conv_0_1    307200     \n",
            "features_9_conv_1_0    1382400    \n",
            "features_9_conv_1_1    307200     \n",
            "features_9_conv_2      9830400    \n",
            "features_9_conv_3      51200      \n",
            "add_4                  51200      \n",
            "features_10_conv_0_0   9830400    \n",
            "features_10_conv_0_1   307200     \n",
            "features_10_conv_1_0   1382400    \n",
            "features_10_conv_1_1   307200     \n",
            "features_10_conv_2     9830400    \n",
            "features_10_conv_3     51200      \n",
            "add_5                  51200      \n",
            "features_11_conv_0_0   9830400    \n",
            "features_11_conv_0_1   307200     \n",
            "features_11_conv_1_0   1382400    \n",
            "features_11_conv_1_1   307200     \n",
            "features_11_conv_2     14745600   \n",
            "features_11_conv_3     76800      \n",
            "features_12_conv_0_0   22118400   \n",
            "features_12_conv_0_1   460800     \n",
            "features_12_conv_1_0   2073600    \n",
            "features_12_conv_1_1   460800     \n",
            "features_12_conv_2     22118400   \n",
            "features_12_conv_3     76800      \n",
            "add_6                  76800      \n",
            "features_13_conv_0_0   22118400   \n",
            "features_13_conv_0_1   460800     \n",
            "features_13_conv_1_0   2073600    \n",
            "features_13_conv_1_1   460800     \n",
            "features_13_conv_2     22118400   \n",
            "features_13_conv_3     76800      \n",
            "add_7                  76800      \n",
            "features_14_conv_0_0   22118400   \n",
            "features_14_conv_0_1   460800     \n",
            "features_14_conv_1_0   518400     \n",
            "features_14_conv_1_1   115200     \n",
            "features_14_conv_2     9216000    \n",
            "features_14_conv_3     32000      \n",
            "features_15_conv_0_0   15360000   \n",
            "features_15_conv_0_1   192000     \n",
            "features_15_conv_1_0   864000     \n",
            "features_15_conv_1_1   192000     \n",
            "features_15_conv_2     15360000   \n",
            "features_15_conv_3     32000      \n",
            "add_8                  32000      \n",
            "features_16_conv_0_0   15360000   \n",
            "features_16_conv_0_1   192000     \n",
            "features_16_conv_1_0   864000     \n",
            "features_16_conv_1_1   192000     \n",
            "features_16_conv_2     15360000   \n",
            "features_16_conv_3     32000      \n",
            "add_9                  32000      \n",
            "features_17_conv_0_0   15360000   \n",
            "features_17_conv_0_1   192000     \n",
            "features_17_conv_1_0   864000     \n",
            "features_17_conv_1_1   192000     \n",
            "features_17_conv_2     30720000   \n",
            "features_17_conv_3     64000      \n",
            "features_18_0          40960000   \n",
            "features_18_1          256000     \n",
            "classifier_1           1281000    \n",
            "--------------------   --------   \n",
            "Input size: (1, 3, 317, 317)\n",
            "639,501,512 FLOPs or approx. 0.64 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "phi = 1\n",
        "\"\"\"\n",
        "phi = 1\n",
        "mul = math.pow(math.sqrt(2),phi)\n",
        "ip = torch.rand(1,3,math.ceil(mul*224),math.ceil(mul*224)).to(dev)\n",
        "temp = count_ops(model_mobilenet, ip) # Count the number of FLOPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ2clnrwVzfH",
        "outputId": "4f153a3e-3e08-475f-8650-2aefe94e10cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operation              OPS        \n",
            "---------------------  ---------  \n",
            "features_0_0           43740000   \n",
            "features_0_1           3240000    \n",
            "features_1_conv_0_0    14580000   \n",
            "features_1_conv_0_1    3240000    \n",
            "features_1_conv_1      25920000   \n",
            "features_1_conv_2      1620000    \n",
            "features_2_conv_0_0    77760000   \n",
            "features_2_conv_0_1    9720000    \n",
            "features_2_conv_1_0    11032416   \n",
            "features_2_conv_1_1    2451648    \n",
            "features_2_conv_2      29419776   \n",
            "features_2_conv_3      612912     \n",
            "features_3_conv_0_0    44129664   \n",
            "features_3_conv_0_1    3677472    \n",
            "features_3_conv_1_0    16548624   \n",
            "features_3_conv_1_1    3677472    \n",
            "features_3_conv_2      44129664   \n",
            "features_3_conv_3      612912     \n",
            "add                    612912     \n",
            "features_4_conv_0_0    44129664   \n",
            "features_4_conv_0_1    3677472    \n",
            "features_4_conv_1_0    4210704    \n",
            "features_4_conv_1_1    935712     \n",
            "features_4_conv_2      14971392   \n",
            "features_4_conv_3      207936     \n",
            "features_5_conv_0_0    19961856   \n",
            "features_5_conv_0_1    1247616    \n",
            "features_5_conv_1_0    5614272    \n",
            "features_5_conv_1_1    1247616    \n",
            "features_5_conv_2      19961856   \n",
            "features_5_conv_3      207936     \n",
            "add_1                  207936     \n",
            "features_6_conv_0_0    19961856   \n",
            "features_6_conv_0_1    1247616    \n",
            "features_6_conv_1_0    5614272    \n",
            "features_6_conv_1_1    1247616    \n",
            "features_6_conv_2      19961856   \n",
            "features_6_conv_3      207936     \n",
            "add_2                  207936     \n",
            "features_7_conv_0_0    19961856   \n",
            "features_7_conv_0_1    1247616    \n",
            "features_7_conv_1_0    1453248    \n",
            "features_7_conv_1_1    322944     \n",
            "features_7_conv_2      10334208   \n",
            "features_7_conv_3      107648     \n",
            "features_8_conv_0_0    20668416   \n",
            "features_8_conv_0_1    645888     \n",
            "features_8_conv_1_0    2906496    \n",
            "features_8_conv_1_1    645888     \n",
            "features_8_conv_2      20668416   \n",
            "features_8_conv_3      107648     \n",
            "add_3                  107648     \n",
            "features_9_conv_0_0    20668416   \n",
            "features_9_conv_0_1    645888     \n",
            "features_9_conv_1_0    2906496    \n",
            "features_9_conv_1_1    645888     \n",
            "features_9_conv_2      20668416   \n",
            "features_9_conv_3      107648     \n",
            "add_4                  107648     \n",
            "features_10_conv_0_0   20668416   \n",
            "features_10_conv_0_1   645888     \n",
            "features_10_conv_1_0   2906496    \n",
            "features_10_conv_1_1   645888     \n",
            "features_10_conv_2     20668416   \n",
            "features_10_conv_3     107648     \n",
            "add_5                  107648     \n",
            "features_11_conv_0_0   20668416   \n",
            "features_11_conv_0_1   645888     \n",
            "features_11_conv_1_0   2906496    \n",
            "features_11_conv_1_1   645888     \n",
            "features_11_conv_2     31002624   \n",
            "features_11_conv_3     161472     \n",
            "features_12_conv_0_0   46503936   \n",
            "features_12_conv_0_1   968832     \n",
            "features_12_conv_1_0   4359744    \n",
            "features_12_conv_1_1   968832     \n",
            "features_12_conv_2     46503936   \n",
            "features_12_conv_3     161472     \n",
            "add_6                  161472     \n",
            "features_13_conv_0_0   46503936   \n",
            "features_13_conv_0_1   968832     \n",
            "features_13_conv_1_0   4359744    \n",
            "features_13_conv_1_1   968832     \n",
            "features_13_conv_2     46503936   \n",
            "features_13_conv_3     161472     \n",
            "add_7                  161472     \n",
            "features_14_conv_0_0   46503936   \n",
            "features_14_conv_0_1   968832     \n",
            "features_14_conv_1_0   1166400    \n",
            "features_14_conv_1_1   259200     \n",
            "features_14_conv_2     20736000   \n",
            "features_14_conv_3     72000      \n",
            "features_15_conv_0_0   34560000   \n",
            "features_15_conv_0_1   432000     \n",
            "features_15_conv_1_0   1944000    \n",
            "features_15_conv_1_1   432000     \n",
            "features_15_conv_2     34560000   \n",
            "features_15_conv_3     72000      \n",
            "add_8                  72000      \n",
            "features_16_conv_0_0   34560000   \n",
            "features_16_conv_0_1   432000     \n",
            "features_16_conv_1_0   1944000    \n",
            "features_16_conv_1_1   432000     \n",
            "features_16_conv_2     34560000   \n",
            "features_16_conv_3     72000      \n",
            "add_9                  72000      \n",
            "features_17_conv_0_0   34560000   \n",
            "features_17_conv_0_1   432000     \n",
            "features_17_conv_1_0   1944000    \n",
            "features_17_conv_1_1   432000     \n",
            "features_17_conv_2     69120000   \n",
            "features_17_conv_3     144000     \n",
            "features_18_0          92160000   \n",
            "features_18_1          576000     \n",
            "classifier_1           1281000    \n",
            "--------------------   --------   \n",
            "Input size: (1, 3, 449, 449)\n",
            "1,342,221,848 FLOPs or approx. 1.34 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "phi = 2\n",
        "\"\"\"\n",
        "phi = 2\n",
        "mul = math.pow(math.sqrt(2),phi)\n",
        "ip = torch.rand(1,3,math.ceil(mul*224),math.ceil(mul*224)).to(dev)\n",
        "temp = count_ops(model_mobilenet, ip) # Count the number of FLOPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH8dqHCbVzhf",
        "outputId": "45e526ae-51a6-44ce-8000-b986b544c1c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operation              OPS         \n",
            "---------------------  ----------  \n",
            "features_0_0           86822496    \n",
            "features_0_1           6431296     \n",
            "features_1_conv_0_0    28940832    \n",
            "features_1_conv_0_1    6431296     \n",
            "features_1_conv_1      51450368    \n",
            "features_1_conv_2      3215648     \n",
            "features_2_conv_0_0    154351104   \n",
            "features_2_conv_0_1    19293888    \n",
            "features_2_conv_1_0    21842784    \n",
            "features_2_conv_1_1    4853952     \n",
            "features_2_conv_2      58247424    \n",
            "features_2_conv_3      1213488     \n",
            "features_3_conv_0_0    87371136    \n",
            "features_3_conv_0_1    7280928     \n",
            "features_3_conv_1_0    32764176    \n",
            "features_3_conv_1_1    7280928     \n",
            "features_3_conv_2      87371136    \n",
            "features_3_conv_3      1213488     \n",
            "add                    1213488     \n",
            "features_4_conv_0_0    87371136    \n",
            "features_4_conv_0_1    7280928     \n",
            "features_4_conv_1_0    8294400     \n",
            "features_4_conv_1_1    1843200     \n",
            "features_4_conv_2      29491200    \n",
            "features_4_conv_3      409600      \n",
            "features_5_conv_0_0    39321600    \n",
            "features_5_conv_0_1    2457600     \n",
            "features_5_conv_1_0    11059200    \n",
            "features_5_conv_1_1    2457600     \n",
            "features_5_conv_2      39321600    \n",
            "features_5_conv_3      409600      \n",
            "add_1                  409600      \n",
            "features_6_conv_0_0    39321600    \n",
            "features_6_conv_0_1    2457600     \n",
            "features_6_conv_1_0    11059200    \n",
            "features_6_conv_1_1    2457600     \n",
            "features_6_conv_2      39321600    \n",
            "features_6_conv_3      409600      \n",
            "add_2                  409600      \n",
            "features_7_conv_0_0    39321600    \n",
            "features_7_conv_0_1    2457600     \n",
            "features_7_conv_1_0    2764800     \n",
            "features_7_conv_1_1    614400      \n",
            "features_7_conv_2      19660800    \n",
            "features_7_conv_3      204800      \n",
            "features_8_conv_0_0    39321600    \n",
            "features_8_conv_0_1    1228800     \n",
            "features_8_conv_1_0    5529600     \n",
            "features_8_conv_1_1    1228800     \n",
            "features_8_conv_2      39321600    \n",
            "features_8_conv_3      204800      \n",
            "add_3                  204800      \n",
            "features_9_conv_0_0    39321600    \n",
            "features_9_conv_0_1    1228800     \n",
            "features_9_conv_1_0    5529600     \n",
            "features_9_conv_1_1    1228800     \n",
            "features_9_conv_2      39321600    \n",
            "features_9_conv_3      204800      \n",
            "add_4                  204800      \n",
            "features_10_conv_0_0   39321600    \n",
            "features_10_conv_0_1   1228800     \n",
            "features_10_conv_1_0   5529600     \n",
            "features_10_conv_1_1   1228800     \n",
            "features_10_conv_2     39321600    \n",
            "features_10_conv_3     204800      \n",
            "add_5                  204800      \n",
            "features_11_conv_0_0   39321600    \n",
            "features_11_conv_0_1   1228800     \n",
            "features_11_conv_1_0   5529600     \n",
            "features_11_conv_1_1   1228800     \n",
            "features_11_conv_2     58982400    \n",
            "features_11_conv_3     307200      \n",
            "features_12_conv_0_0   88473600    \n",
            "features_12_conv_0_1   1843200     \n",
            "features_12_conv_1_0   8294400     \n",
            "features_12_conv_1_1   1843200     \n",
            "features_12_conv_2     88473600    \n",
            "features_12_conv_3     307200      \n",
            "add_6                  307200      \n",
            "features_13_conv_0_0   88473600    \n",
            "features_13_conv_0_1   1843200     \n",
            "features_13_conv_1_0   8294400     \n",
            "features_13_conv_1_1   1843200     \n",
            "features_13_conv_2     88473600    \n",
            "features_13_conv_3     307200      \n",
            "add_7                  307200      \n",
            "features_14_conv_0_0   88473600    \n",
            "features_14_conv_0_1   1843200     \n",
            "features_14_conv_1_0   2073600     \n",
            "features_14_conv_1_1   460800      \n",
            "features_14_conv_2     36864000    \n",
            "features_14_conv_3     128000      \n",
            "features_15_conv_0_0   61440000    \n",
            "features_15_conv_0_1   768000      \n",
            "features_15_conv_1_0   3456000     \n",
            "features_15_conv_1_1   768000      \n",
            "features_15_conv_2     61440000    \n",
            "features_15_conv_3     128000      \n",
            "add_8                  128000      \n",
            "features_16_conv_0_0   61440000    \n",
            "features_16_conv_0_1   768000      \n",
            "features_16_conv_1_0   3456000     \n",
            "features_16_conv_1_1   768000      \n",
            "features_16_conv_2     61440000    \n",
            "features_16_conv_3     128000      \n",
            "add_9                  128000      \n",
            "features_17_conv_0_0   61440000    \n",
            "features_17_conv_0_1   768000      \n",
            "features_17_conv_1_0   3456000     \n",
            "features_17_conv_1_1   768000      \n",
            "features_17_conv_2     122880000   \n",
            "features_17_conv_3     256000      \n",
            "features_18_0          163840000   \n",
            "features_18_1          1024000     \n",
            "classifier_1           1281000     \n",
            "--------------------   ---------   \n",
            "Input size: (1, 3, 634, 634)\n",
            "2,546,793,320 FLOPs or approx. 2.55 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "phi = 3\n",
        "\"\"\"\n",
        "phi = 3\n",
        "mul = math.pow(math.sqrt(2),phi)\n",
        "ip = torch.rand(1,3,math.ceil(mul*224),math.ceil(mul*224)).to(dev)\n",
        "temp = count_ops(model_mobilenet, ip) # Count the number of FLOPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DZ54B9dVzks",
        "outputId": "95e77e99-2f15-4d1f-c93f-473032d0bade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operation              OPS         \n",
            "---------------------  ----------  \n",
            "features_0_0           174183264   \n",
            "features_0_1           12902464    \n",
            "features_1_conv_0_0    58061088    \n",
            "features_1_conv_0_1    12902464    \n",
            "features_1_conv_1      103219712   \n",
            "features_1_conv_2      6451232     \n",
            "features_2_conv_0_0    309659136   \n",
            "features_2_conv_0_1    38707392    \n",
            "features_2_conv_1_0    43740000    \n",
            "features_2_conv_1_1    9720000     \n",
            "features_2_conv_2      116640000   \n",
            "features_2_conv_3      2430000     \n",
            "features_3_conv_0_0    174960000   \n",
            "features_3_conv_0_1    14580000    \n",
            "features_3_conv_1_0    65610000    \n",
            "features_3_conv_1_1    14580000    \n",
            "features_3_conv_2      174960000   \n",
            "features_3_conv_3      2430000     \n",
            "add                    2430000     \n",
            "features_4_conv_0_0    174960000   \n",
            "features_4_conv_0_1    14580000    \n",
            "features_4_conv_1_0    16548624    \n",
            "features_4_conv_1_1    3677472     \n",
            "features_4_conv_2      58839552    \n",
            "features_4_conv_3      817216      \n",
            "features_5_conv_0_0    78452736    \n",
            "features_5_conv_0_1    4903296     \n",
            "features_5_conv_1_0    22064832    \n",
            "features_5_conv_1_1    4903296     \n",
            "features_5_conv_2      78452736    \n",
            "features_5_conv_3      817216      \n",
            "add_1                  817216      \n",
            "features_6_conv_0_0    78452736    \n",
            "features_6_conv_0_1    4903296     \n",
            "features_6_conv_1_0    22064832    \n",
            "features_6_conv_1_1    4903296     \n",
            "features_6_conv_2      78452736    \n",
            "features_6_conv_3      817216      \n",
            "add_2                  817216      \n",
            "features_7_conv_0_0    78452736    \n",
            "features_7_conv_0_1    4903296     \n",
            "features_7_conv_1_0    5614272     \n",
            "features_7_conv_1_1    1247616     \n",
            "features_7_conv_2      39923712    \n",
            "features_7_conv_3      415872      \n",
            "features_8_conv_0_0    79847424    \n",
            "features_8_conv_0_1    2495232     \n",
            "features_8_conv_1_0    11228544    \n",
            "features_8_conv_1_1    2495232     \n",
            "features_8_conv_2      79847424    \n",
            "features_8_conv_3      415872      \n",
            "add_3                  415872      \n",
            "features_9_conv_0_0    79847424    \n",
            "features_9_conv_0_1    2495232     \n",
            "features_9_conv_1_0    11228544    \n",
            "features_9_conv_1_1    2495232     \n",
            "features_9_conv_2      79847424    \n",
            "features_9_conv_3      415872      \n",
            "add_4                  415872      \n",
            "features_10_conv_0_0   79847424    \n",
            "features_10_conv_0_1   2495232     \n",
            "features_10_conv_1_0   11228544    \n",
            "features_10_conv_1_1   2495232     \n",
            "features_10_conv_2     79847424    \n",
            "features_10_conv_3     415872      \n",
            "add_5                  415872      \n",
            "features_11_conv_0_0   79847424    \n",
            "features_11_conv_0_1   2495232     \n",
            "features_11_conv_1_0   11228544    \n",
            "features_11_conv_1_1   2495232     \n",
            "features_11_conv_2     119771136   \n",
            "features_11_conv_3     623808      \n",
            "features_12_conv_0_0   179656704   \n",
            "features_12_conv_0_1   3742848     \n",
            "features_12_conv_1_0   16842816    \n",
            "features_12_conv_1_1   3742848     \n",
            "features_12_conv_2     179656704   \n",
            "features_12_conv_3     623808      \n",
            "add_6                  623808      \n",
            "features_13_conv_0_0   179656704   \n",
            "features_13_conv_0_1   3742848     \n",
            "features_13_conv_1_0   16842816    \n",
            "features_13_conv_1_1   3742848     \n",
            "features_13_conv_2     179656704   \n",
            "features_13_conv_3     623808      \n",
            "add_7                  623808      \n",
            "features_14_conv_0_0   179656704   \n",
            "features_14_conv_0_1   3742848     \n",
            "features_14_conv_1_0   4359744     \n",
            "features_14_conv_1_1   968832      \n",
            "features_14_conv_2     77506560    \n",
            "features_14_conv_3     269120      \n",
            "features_15_conv_0_0   129177600   \n",
            "features_15_conv_0_1   1614720     \n",
            "features_15_conv_1_0   7266240     \n",
            "features_15_conv_1_1   1614720     \n",
            "features_15_conv_2     129177600   \n",
            "features_15_conv_3     269120      \n",
            "add_8                  269120      \n",
            "features_16_conv_0_0   129177600   \n",
            "features_16_conv_0_1   1614720     \n",
            "features_16_conv_1_0   7266240     \n",
            "features_16_conv_1_1   1614720     \n",
            "features_16_conv_2     129177600   \n",
            "features_16_conv_3     269120      \n",
            "add_9                  269120      \n",
            "features_17_conv_0_0   129177600   \n",
            "features_17_conv_0_1   1614720     \n",
            "features_17_conv_1_0   7266240     \n",
            "features_17_conv_1_1   1614720     \n",
            "features_17_conv_2     258355200   \n",
            "features_17_conv_3     538240      \n",
            "features_18_0          344473600   \n",
            "features_18_1          2152960     \n",
            "classifier_1           1281000     \n",
            "--------------------   ---------   \n",
            "Input size: (1, 3, 897, 897)\n",
            "5,187,203,352 FLOPs or approx. 5.19 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "phi = 4\n",
        "\"\"\"\n",
        "phi = 4\n",
        "mul = math.pow(math.sqrt(2),phi)\n",
        "ip = torch.rand(1,3,math.ceil(mul*224),math.ceil(mul*224)).to(dev)\n",
        "temp = count_ops(model_mobilenet, ip) # Count the number of FLOPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIpZ1xyhVzn9",
        "outputId": "91431626-d275-4be7-a8e4-7a4c1cc91a4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operation              OPS         \n",
            "---------------------  ----------  \n",
            "features_0_0           347289984   \n",
            "features_0_1           25725184    \n",
            "features_1_conv_0_0    115763328   \n",
            "features_1_conv_0_1    25725184    \n",
            "features_1_conv_1      205801472   \n",
            "features_1_conv_2      12862592    \n",
            "features_2_conv_0_0    617404416   \n",
            "features_2_conv_0_1    77175552    \n",
            "features_2_conv_1_0    86822496    \n",
            "features_2_conv_1_1    19293888    \n",
            "features_2_conv_2      231526656   \n",
            "features_2_conv_3      4823472     \n",
            "features_3_conv_0_0    347289984   \n",
            "features_3_conv_0_1    28940832    \n",
            "features_3_conv_1_0    130233744   \n",
            "features_3_conv_1_1    28940832    \n",
            "features_3_conv_2      347289984   \n",
            "features_3_conv_3      4823472     \n",
            "add                    4823472     \n",
            "features_4_conv_0_0    347289984   \n",
            "features_4_conv_0_1    28940832    \n",
            "features_4_conv_1_0    32764176    \n",
            "features_4_conv_1_1    7280928     \n",
            "features_4_conv_2      116494848   \n",
            "features_4_conv_3      1617984     \n",
            "features_5_conv_0_0    155326464   \n",
            "features_5_conv_0_1    9707904     \n",
            "features_5_conv_1_0    43685568    \n",
            "features_5_conv_1_1    9707904     \n",
            "features_5_conv_2      155326464   \n",
            "features_5_conv_3      1617984     \n",
            "add_1                  1617984     \n",
            "features_6_conv_0_0    155326464   \n",
            "features_6_conv_0_1    9707904     \n",
            "features_6_conv_1_0    43685568    \n",
            "features_6_conv_1_1    9707904     \n",
            "features_6_conv_2      155326464   \n",
            "features_6_conv_3      1617984     \n",
            "add_2                  1617984     \n",
            "features_7_conv_0_0    155326464   \n",
            "features_7_conv_0_1    9707904     \n",
            "features_7_conv_1_0    11059200    \n",
            "features_7_conv_1_1    2457600     \n",
            "features_7_conv_2      78643200    \n",
            "features_7_conv_3      819200      \n",
            "features_8_conv_0_0    157286400   \n",
            "features_8_conv_0_1    4915200     \n",
            "features_8_conv_1_0    22118400    \n",
            "features_8_conv_1_1    4915200     \n",
            "features_8_conv_2      157286400   \n",
            "features_8_conv_3      819200      \n",
            "add_3                  819200      \n",
            "features_9_conv_0_0    157286400   \n",
            "features_9_conv_0_1    4915200     \n",
            "features_9_conv_1_0    22118400    \n",
            "features_9_conv_1_1    4915200     \n",
            "features_9_conv_2      157286400   \n",
            "features_9_conv_3      819200      \n",
            "add_4                  819200      \n",
            "features_10_conv_0_0   157286400   \n",
            "features_10_conv_0_1   4915200     \n",
            "features_10_conv_1_0   22118400    \n",
            "features_10_conv_1_1   4915200     \n",
            "features_10_conv_2     157286400   \n",
            "features_10_conv_3     819200      \n",
            "add_5                  819200      \n",
            "features_11_conv_0_0   157286400   \n",
            "features_11_conv_0_1   4915200     \n",
            "features_11_conv_1_0   22118400    \n",
            "features_11_conv_1_1   4915200     \n",
            "features_11_conv_2     235929600   \n",
            "features_11_conv_3     1228800     \n",
            "features_12_conv_0_0   353894400   \n",
            "features_12_conv_0_1   7372800     \n",
            "features_12_conv_1_0   33177600    \n",
            "features_12_conv_1_1   7372800     \n",
            "features_12_conv_2     353894400   \n",
            "features_12_conv_3     1228800     \n",
            "add_6                  1228800     \n",
            "features_13_conv_0_0   353894400   \n",
            "features_13_conv_0_1   7372800     \n",
            "features_13_conv_1_0   33177600    \n",
            "features_13_conv_1_1   7372800     \n",
            "features_13_conv_2     353894400   \n",
            "features_13_conv_3     1228800     \n",
            "add_7                  1228800     \n",
            "features_14_conv_0_0   353894400   \n",
            "features_14_conv_0_1   7372800     \n",
            "features_14_conv_1_0   8294400     \n",
            "features_14_conv_1_1   1843200     \n",
            "features_14_conv_2     147456000   \n",
            "features_14_conv_3     512000      \n",
            "features_15_conv_0_0   245760000   \n",
            "features_15_conv_0_1   3072000     \n",
            "features_15_conv_1_0   13824000    \n",
            "features_15_conv_1_1   3072000     \n",
            "features_15_conv_2     245760000   \n",
            "features_15_conv_3     512000      \n",
            "add_8                  512000      \n",
            "features_16_conv_0_0   245760000   \n",
            "features_16_conv_0_1   3072000     \n",
            "features_16_conv_1_0   13824000    \n",
            "features_16_conv_1_1   3072000     \n",
            "features_16_conv_2     245760000   \n",
            "features_16_conv_3     512000      \n",
            "add_9                  512000      \n",
            "features_17_conv_0_0   245760000   \n",
            "features_17_conv_0_1   3072000     \n",
            "features_17_conv_1_0   13824000    \n",
            "features_17_conv_1_1   3072000     \n",
            "features_17_conv_2     491520000   \n",
            "features_17_conv_3     1024000     \n",
            "features_18_0          655360000   \n",
            "features_18_1          4096000     \n",
            "classifier_1           1281000     \n",
            "--------------------   ---------   \n",
            "Input size: (1, 3, 1268, 1268)\n",
            "10,159,558,008 FLOPs or approx. 10.16 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "phi = 5\n",
        "\"\"\"\n",
        "phi = 5\n",
        "mul = math.pow(math.sqrt(2),phi)\n",
        "ip = torch.rand(1,3,math.ceil(mul*224),math.ceil(mul*224)).to(dev)\n",
        "temp = count_ops(model_mobilenet, ip) # Count the number of FLOPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nBibkEvVzqR",
        "outputId": "4993c30e-22c5-4f40-84ef-0515d2aa1e74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operation              OPS          \n",
            "---------------------  -----------  \n",
            "features_0_0           695182176    \n",
            "features_0_1           51494976     \n",
            "features_1_conv_0_0    231727392    \n",
            "features_1_conv_0_1    51494976     \n",
            "features_1_conv_1      411959808    \n",
            "features_1_conv_2      25747488     \n",
            "features_2_conv_0_0    1235879424   \n",
            "features_2_conv_0_1    154484928    \n",
            "features_2_conv_1_0    174183264    \n",
            "features_2_conv_1_1    38707392     \n",
            "features_2_conv_2      464488704    \n",
            "features_2_conv_3      9676848      \n",
            "features_3_conv_0_0    696733056    \n",
            "features_3_conv_0_1    58061088     \n",
            "features_3_conv_1_0    261274896    \n",
            "features_3_conv_1_1    58061088     \n",
            "features_3_conv_2      696733056    \n",
            "features_3_conv_3      9676848      \n",
            "add                    9676848      \n",
            "features_4_conv_0_0    696733056    \n",
            "features_4_conv_0_1    58061088     \n",
            "features_4_conv_1_0    65610000     \n",
            "features_4_conv_1_1    14580000     \n",
            "features_4_conv_2      233280000    \n",
            "features_4_conv_3      3240000      \n",
            "features_5_conv_0_0    311040000    \n",
            "features_5_conv_0_1    19440000     \n",
            "features_5_conv_1_0    87480000     \n",
            "features_5_conv_1_1    19440000     \n",
            "features_5_conv_2      311040000    \n",
            "features_5_conv_3      3240000      \n",
            "add_1                  3240000      \n",
            "features_6_conv_0_0    311040000    \n",
            "features_6_conv_0_1    19440000     \n",
            "features_6_conv_1_0    87480000     \n",
            "features_6_conv_1_1    19440000     \n",
            "features_6_conv_2      311040000    \n",
            "features_6_conv_3      3240000      \n",
            "add_2                  3240000      \n",
            "features_7_conv_0_0    311040000    \n",
            "features_7_conv_0_1    19440000     \n",
            "features_7_conv_1_0    22064832     \n",
            "features_7_conv_1_1    4903296      \n",
            "features_7_conv_2      156905472    \n",
            "features_7_conv_3      1634432      \n",
            "features_8_conv_0_0    313810944    \n",
            "features_8_conv_0_1    9806592      \n",
            "features_8_conv_1_0    44129664     \n",
            "features_8_conv_1_1    9806592      \n",
            "features_8_conv_2      313810944    \n",
            "features_8_conv_3      1634432      \n",
            "add_3                  1634432      \n",
            "features_9_conv_0_0    313810944    \n",
            "features_9_conv_0_1    9806592      \n",
            "features_9_conv_1_0    44129664     \n",
            "features_9_conv_1_1    9806592      \n",
            "features_9_conv_2      313810944    \n",
            "features_9_conv_3      1634432      \n",
            "add_4                  1634432      \n",
            "features_10_conv_0_0   313810944    \n",
            "features_10_conv_0_1   9806592      \n",
            "features_10_conv_1_0   44129664     \n",
            "features_10_conv_1_1   9806592      \n",
            "features_10_conv_2     313810944    \n",
            "features_10_conv_3     1634432      \n",
            "add_5                  1634432      \n",
            "features_11_conv_0_0   313810944    \n",
            "features_11_conv_0_1   9806592      \n",
            "features_11_conv_1_0   44129664     \n",
            "features_11_conv_1_1   9806592      \n",
            "features_11_conv_2     470716416    \n",
            "features_11_conv_3     2451648      \n",
            "features_12_conv_0_0   706074624    \n",
            "features_12_conv_0_1   14709888     \n",
            "features_12_conv_1_0   66194496     \n",
            "features_12_conv_1_1   14709888     \n",
            "features_12_conv_2     706074624    \n",
            "features_12_conv_3     2451648      \n",
            "add_6                  2451648      \n",
            "features_13_conv_0_0   706074624    \n",
            "features_13_conv_0_1   14709888     \n",
            "features_13_conv_1_0   66194496     \n",
            "features_13_conv_1_1   14709888     \n",
            "features_13_conv_2     706074624    \n",
            "features_13_conv_3     2451648      \n",
            "add_7                  2451648      \n",
            "features_14_conv_0_0   706074624    \n",
            "features_14_conv_0_1   14709888     \n",
            "features_14_conv_1_0   16842816     \n",
            "features_14_conv_1_1   3742848      \n",
            "features_14_conv_2     299427840    \n",
            "features_14_conv_3     1039680      \n",
            "features_15_conv_0_0   499046400    \n",
            "features_15_conv_0_1   6238080      \n",
            "features_15_conv_1_0   28071360     \n",
            "features_15_conv_1_1   6238080      \n",
            "features_15_conv_2     499046400    \n",
            "features_15_conv_3     1039680      \n",
            "add_8                  1039680      \n",
            "features_16_conv_0_0   499046400    \n",
            "features_16_conv_0_1   6238080      \n",
            "features_16_conv_1_0   28071360     \n",
            "features_16_conv_1_1   6238080      \n",
            "features_16_conv_2     499046400    \n",
            "features_16_conv_3     1039680      \n",
            "add_9                  1039680      \n",
            "features_17_conv_0_0   499046400    \n",
            "features_17_conv_0_1   6238080      \n",
            "features_17_conv_1_0   28071360     \n",
            "features_17_conv_1_1   6238080      \n",
            "features_17_conv_2     998092800    \n",
            "features_17_conv_3     2079360      \n",
            "features_18_0          1330790400   \n",
            "features_18_1          8317440      \n",
            "classifier_1           1281000      \n",
            "--------------------   ----------   \n",
            "Input size: (1, 3, 1793, 1793)\n",
            "20,395,964,696 FLOPs or approx. 20.40 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "phi = 6\n",
        "\"\"\"\n",
        "phi = 6\n",
        "mul = math.pow(math.sqrt(2),phi)\n",
        "ip = torch.rand(1,3,math.ceil(mul*224),math.ceil(mul*224)).to(dev)\n",
        "temp = count_ops(model_mobilenet, ip) # Count the number of FLOPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8gAk10rVzsY",
        "outputId": "4e0e772c-6d2c-4992-8f0e-436176da1787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Operation              OPS          \n",
            "---------------------  -----------  \n",
            "features_0_0           1389159936   \n",
            "features_0_1           102900736    \n",
            "features_1_conv_0_0    463053312    \n",
            "features_1_conv_0_1    102900736    \n",
            "features_1_conv_1      823205888    \n",
            "features_1_conv_2      51450368     \n",
            "features_2_conv_0_0    2469617664   \n",
            "features_2_conv_0_1    308702208    \n",
            "features_2_conv_1_0    347289984    \n",
            "features_2_conv_1_1    77175552     \n",
            "features_2_conv_2      926106624    \n",
            "features_2_conv_3      19293888     \n",
            "features_3_conv_0_0    1389159936   \n",
            "features_3_conv_0_1    115763328    \n",
            "features_3_conv_1_0    520934976    \n",
            "features_3_conv_1_1    115763328    \n",
            "features_3_conv_2      1389159936   \n",
            "features_3_conv_3      19293888     \n",
            "add                    19293888     \n",
            "features_4_conv_0_0    1389159936   \n",
            "features_4_conv_0_1    115763328    \n",
            "features_4_conv_1_0    130233744    \n",
            "features_4_conv_1_1    28940832     \n",
            "features_4_conv_2      463053312    \n",
            "features_4_conv_3      6431296      \n",
            "features_5_conv_0_0    617404416    \n",
            "features_5_conv_0_1    38587776     \n",
            "features_5_conv_1_0    173644992    \n",
            "features_5_conv_1_1    38587776     \n",
            "features_5_conv_2      617404416    \n",
            "features_5_conv_3      6431296      \n",
            "add_1                  6431296      \n",
            "features_6_conv_0_0    617404416    \n",
            "features_6_conv_0_1    38587776     \n",
            "features_6_conv_1_0    173644992    \n",
            "features_6_conv_1_1    38587776     \n",
            "features_6_conv_2      617404416    \n",
            "features_6_conv_3      6431296      \n",
            "add_2                  6431296      \n",
            "features_7_conv_0_0    617404416    \n",
            "features_7_conv_0_1    38587776     \n",
            "features_7_conv_1_0    43685568     \n",
            "features_7_conv_1_1    9707904      \n",
            "features_7_conv_2      310652928    \n",
            "features_7_conv_3      3235968      \n",
            "features_8_conv_0_0    621305856    \n",
            "features_8_conv_0_1    19415808     \n",
            "features_8_conv_1_0    87371136     \n",
            "features_8_conv_1_1    19415808     \n",
            "features_8_conv_2      621305856    \n",
            "features_8_conv_3      3235968      \n",
            "add_3                  3235968      \n",
            "features_9_conv_0_0    621305856    \n",
            "features_9_conv_0_1    19415808     \n",
            "features_9_conv_1_0    87371136     \n",
            "features_9_conv_1_1    19415808     \n",
            "features_9_conv_2      621305856    \n",
            "features_9_conv_3      3235968      \n",
            "add_4                  3235968      \n",
            "features_10_conv_0_0   621305856    \n",
            "features_10_conv_0_1   19415808     \n",
            "features_10_conv_1_0   87371136     \n",
            "features_10_conv_1_1   19415808     \n",
            "features_10_conv_2     621305856    \n",
            "features_10_conv_3     3235968      \n",
            "add_5                  3235968      \n",
            "features_11_conv_0_0   621305856    \n",
            "features_11_conv_0_1   19415808     \n",
            "features_11_conv_1_0   87371136     \n",
            "features_11_conv_1_1   19415808     \n",
            "features_11_conv_2     931958784    \n",
            "features_11_conv_3     4853952      \n",
            "features_12_conv_0_0   1397938176   \n",
            "features_12_conv_0_1   29123712     \n",
            "features_12_conv_1_0   131056704    \n",
            "features_12_conv_1_1   29123712     \n",
            "features_12_conv_2     1397938176   \n",
            "features_12_conv_3     4853952      \n",
            "add_6                  4853952      \n",
            "features_13_conv_0_0   1397938176   \n",
            "features_13_conv_0_1   29123712     \n",
            "features_13_conv_1_0   131056704    \n",
            "features_13_conv_1_1   29123712     \n",
            "features_13_conv_2     1397938176   \n",
            "features_13_conv_3     4853952      \n",
            "add_7                  4853952      \n",
            "features_14_conv_0_0   1397938176   \n",
            "features_14_conv_0_1   29123712     \n",
            "features_14_conv_1_0   33177600     \n",
            "features_14_conv_1_1   7372800      \n",
            "features_14_conv_2     589824000    \n",
            "features_14_conv_3     2048000      \n",
            "features_15_conv_0_0   983040000    \n",
            "features_15_conv_0_1   12288000     \n",
            "features_15_conv_1_0   55296000     \n",
            "features_15_conv_1_1   12288000     \n",
            "features_15_conv_2     983040000    \n",
            "features_15_conv_3     2048000      \n",
            "add_8                  2048000      \n",
            "features_16_conv_0_0   983040000    \n",
            "features_16_conv_0_1   12288000     \n",
            "features_16_conv_1_0   55296000     \n",
            "features_16_conv_1_1   12288000     \n",
            "features_16_conv_2     983040000    \n",
            "features_16_conv_3     2048000      \n",
            "add_9                  2048000      \n",
            "features_17_conv_0_0   983040000    \n",
            "features_17_conv_0_1   12288000     \n",
            "features_17_conv_1_0   55296000     \n",
            "features_17_conv_1_1   12288000     \n",
            "features_17_conv_2     1966080000   \n",
            "features_17_conv_3     4096000      \n",
            "features_18_0          2621440000   \n",
            "features_18_1          16384000     \n",
            "classifier_1           1281000      \n",
            "--------------------   ----------   \n",
            "Input size: (1, 3, 2535, 2535)\n",
            "40,435,797,720 FLOPs or approx. 40.44 GFLOPs\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "phi = 7\n",
        "\"\"\"\n",
        "phi = 7\n",
        "mul = math.pow(math.sqrt(2),phi)\n",
        "ip = torch.rand(1,3,math.ceil(mul*224),math.ceil(mul*224)).to(dev)\n",
        "temp = count_ops(model_mobilenet, ip) # Count the number of FLOPs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "K--Bh2TOdm4h",
        "outputId": "c71f4eff-8161-4b7f-db40-c7d1e6733556"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4fed13a2b0>]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "y = [0.31,0.64,1.34,2.55,5.19,10.16,20.40,40.44] #plotting results in a graph\n",
        "x = [0,1,2,3,4,5,6,7]\n",
        "plt.figure(figsize = (8,4))\n",
        "plt.title(\"IMAGE SCALING MOBILENET__alpha = 1, beta^2 = 1, gamma^2 = 2\")\n",
        "plt.xlabel(\"phi values\")\n",
        "plt.ylabel(\"GFLOPS\")\n",
        "plt.plot(x,y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3TRis6MVzty",
        "outputId": "828a0956-eefd-477e-caa4-32bd9e9169ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "features\n",
            "classifier\n"
          ]
        }
      ],
      "source": [
        "net_m = copy.deepcopy(model_mobilenet)\n",
        "for name, child in net_m.named_children():\n",
        "  print(name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "XecKI_prVzvu"
      },
      "outputs": [],
      "source": [
        "net_m.features[0][0] = nn.Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "net_m.features[0][1] = nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[0][2] = nn.ReLU6(inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "net_m.features[1].conv[0][0] = nn.Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
        "net_m.features[1].conv[0][1] = nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[1].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[1].conv[1] = nn.Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[1].conv[2] = nn.BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "net_m.features[2].conv[0][0] = nn.Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[2].conv[0][1] = nn.BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[2].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[2].conv[1][0] = nn.Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
        "net_m.features[2].conv[1][1] = nn.BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[2].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[2].conv[2] = nn.Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[2].conv[3] = nn.BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "net_m.features[3].conv[0][0] = nn.Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[3].conv[0][1] = nn.BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[3].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[3].conv[1][0] = nn.Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
        "net_m.features[3].conv[1][1] = nn.BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[3].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[3].conv[2] = nn.Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[3].conv[3] = nn.BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "net_m.features[4].conv[0][0] = nn.Conv2d(144, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[4].conv[0][1] = nn.BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[4].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[4].conv[1][0] = nn.Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
        "net_m.features[4].conv[1][1] = nn.BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[4].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[4].conv[2] = nn.Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[4].conv[3] = nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "net_m.features[5].conv[0][0] = nn.Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[5].conv[0][1] = nn.BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[5].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[5].conv[1][0] = nn.Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
        "net_m.features[5].conv[1][1] = nn.BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[5].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[5].conv[2] = nn.Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[5].conv[3] = nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "net_m.features[6].conv[0][0] = nn.Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[6].conv[0][1] = nn.BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[6].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[6].conv[1][0] = nn.Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
        "net_m.features[6].conv[1][1] = nn.BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[6].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[6].conv[2] = nn.Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[6].conv[3] = nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "net_m.features[7].conv[0][0] = nn.Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[7].conv[0][1] = nn.BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[7].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[7].conv[1][0] = nn.Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
        "net_m.features[7].conv[1][1] = nn.BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[7].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[7].conv[2] = nn.Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[7].conv[3] = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "net_m.features[8].conv[0][0] = nn.Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[8].conv[0][1] = nn.BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[8].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[8].conv[1][0] = nn.Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
        "net_m.features[8].conv[1][1] = nn.BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[8].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[8].conv[2] = nn.Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[8].conv[3] = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "net_m.features[9].conv[0][0] = nn.Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[9].conv[0][1] = nn.BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[9].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[9].conv[1][0] = nn.Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
        "net_m.features[9].conv[1][1] = nn.BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[9].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[9].conv[2] = nn.Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[9].conv[3] = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "net_m.features[10].conv[0][0] = nn.Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[10].conv[0][1] = nn.BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[10].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[10].conv[1][0] = nn.Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
        "net_m.features[10].conv[1][1] = nn.BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[10].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[10].conv[2] = nn.Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[10].conv[3] = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "\n",
        "net_m.features[11].conv[0][0] = nn.Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[11].conv[0][1] = nn.BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[11].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[11].conv[1][0] = nn.Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
        "net_m.features[11].conv[1][1] = nn.BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[11].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[11].conv[2] = nn.Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[11].conv[3] = nn.BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "\n",
        "net_m.features[12].conv[0][0] = nn.Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[12].conv[0][1] = nn.BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[12].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[12].conv[1][0] = nn.Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
        "net_m.features[12].conv[1][1] = nn.BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[12].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[12].conv[2] = nn.Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[12].conv[3] = nn.BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "net_m.features[13].conv[0][0] = nn.Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[13].conv[0][1] = nn.BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[13].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[13].conv[1][0] = nn.Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
        "net_m.features[13].conv[1][1] = nn.BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[13].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[13].conv[2] = nn.Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[13].conv[3] = nn.BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "\n",
        "net_m.features[14].conv[0][0] = nn.Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[14].conv[0][1] = nn.BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[14].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[14].conv[1][0] = nn.Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
        "net_m.features[14].conv[1][1] = nn.BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[14].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[14].conv[2] = nn.Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[14].conv[3] = nn.BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "net_m.features[15].conv[0][0] = nn.Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[15].conv[0][1] = nn.BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[15].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[15].conv[1][0] = nn.Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
        "net_m.features[15].conv[1][1] = nn.BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[15].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[15].conv[2] = nn.Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[15].conv[3] = nn.BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "net_m.features[16].conv[0][0] = nn.Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[16].conv[0][1] = nn.BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[16].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[16].conv[1][0] = nn.Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
        "net_m.features[16].conv[1][1] = nn.BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[16].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[16].conv[2] = nn.Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[16].conv[3] = nn.BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "\n",
        "net_m.features[17].conv[0][0] = nn.Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[17].conv[0][1] = nn.BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[17].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[17].conv[1][0] = nn.Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
        "net_m.features[17].conv[1][1] = nn.BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[17].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "net_m.features[17].conv[2] = nn.Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[17].conv[3] = nn.BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "\n",
        "net_m.features[18][0] = nn.Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "net_m.features[18][1] = nn.BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "net_m.features[18][2] = nn.ReLU6(inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVBPJo71pi4I"
      },
      "source": [
        "The following code is for width scaling for phi values from 0 to 7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "UoW4utW7VzzK"
      },
      "outputs": [],
      "source": [
        "y_val_mobilenet_width_scaling = []\n",
        "x_val_mobilenet_width_scaling = [0,1,2,3,4,5,6,7]\n",
        "\n",
        "for each in x_val_mobilenet_width_scaling:\n",
        "  phi = math.pow(math.sqrt(2), each)\n",
        "\n",
        "  net_m.features[0][0] = nn.Conv2d(3, math.ceil(phi*32), kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "  net_m.features[0][1] = nn.BatchNorm2d(math.ceil(phi*32), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[0][2] = nn.ReLU6(inplace=True)\n",
        "\n",
        "  net_m.features[1].conv[0][0] = nn.Conv2d(math.ceil(phi*32), math.ceil(phi*32), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=math.ceil(phi*32), bias=False)\n",
        "  net_m.features[1].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*32), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[1].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[1].conv[1] = nn.Conv2d(math.ceil(phi*32), math.ceil(phi*16), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[1].conv[2] = nn.BatchNorm2d(math.ceil(phi*16), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[2].conv[0][0] = nn.Conv2d(math.ceil(phi*16), math.ceil(phi*96), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[2].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*96), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[2].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[2].conv[1][0] = nn.Conv2d(math.ceil(phi*96), math.ceil(phi*96), kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=math.ceil(phi*96), bias=False)\n",
        "  net_m.features[2].conv[1][1] = nn.BatchNorm2d(math.ceil(phi*96), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[2].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[2].conv[2] = nn.Conv2d(math.ceil(phi*96), math.ceil(phi*24), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[2].conv[3] = nn.BatchNorm2d(math.ceil(phi*24), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[3].conv[0][0] = nn.Conv2d(math.ceil(phi*24), math.ceil(phi*144), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[3].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*144), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[3].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[3].conv[1][0] = nn.Conv2d(math.ceil(phi*144), math.ceil(phi*144), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=math.ceil(phi*144), bias=False)\n",
        "  net_m.features[3].conv[1][1] = nn.BatchNorm2d(math.ceil(phi*144), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[3].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[3].conv[2] = nn.Conv2d(math.ceil(phi*144), math.ceil(phi*24), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[3].conv[3] = nn.BatchNorm2d(math.ceil(phi*24), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[4].conv[0][0] = nn.Conv2d(math.ceil(phi*144), math.ceil(phi*144), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[4].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*144), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[4].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[4].conv[1][0] = nn.Conv2d(math.ceil(phi*144), math.ceil(phi*144), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=math.ceil(phi*144), bias=False)\n",
        "  net_m.features[4].conv[1][1] = nn.BatchNorm2d(math.ceil(phi*144), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[4].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[4].conv[2] = nn.Conv2d(math.ceil(phi*144), math.ceil(phi*32), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[4].conv[3] = nn.BatchNorm2d(math.ceil(phi*32), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[5].conv[0][0] = nn.Conv2d(math.ceil(phi*32), math.ceil(phi*192), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[5].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*192), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[5].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[5].conv[1][0] = nn.Conv2d(math.ceil(phi*192), math.ceil(phi*192), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=math.ceil(phi*192), bias=False)\n",
        "  net_m.features[5].conv[1][1] = nn.BatchNorm2d(math.ceil(phi*192), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[5].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[5].conv[2] = nn.Conv2d(math.ceil(phi*192), math.ceil(phi*32), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[5].conv[3] = nn.BatchNorm2d(math.ceil(phi*32), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[6].conv[0][0] = nn.Conv2d(math.ceil(phi*32), math.ceil(phi*192), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[6].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*192), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[6].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[6].conv[1][0] = nn.Conv2d(math.ceil(phi*192), math.ceil(phi*192), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=math.ceil(phi*192), bias=False)\n",
        "  net_m.features[6].conv[1][1] = nn.BatchNorm2d(math.ceil(phi*192), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[6].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[6].conv[2] = nn.Conv2d(math.ceil(phi*192), math.ceil(phi*32), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[6].conv[3] = nn.BatchNorm2d(math.ceil(phi*32), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[7].conv[0][0] = nn.Conv2d(math.ceil(phi*32), math.ceil(phi*192), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[7].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*192), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[7].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[7].conv[1][0] = nn.Conv2d(math.ceil(phi*192), math.ceil(phi*192), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=math.ceil(phi*192), bias=False)\n",
        "  net_m.features[7].conv[1][1] = nn.BatchNorm2d(math.ceil(phi*192), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[7].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[7].conv[2] = nn.Conv2d(math.ceil(phi*192), math.ceil(phi*64), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[7].conv[3] = nn.BatchNorm2d(math.ceil(phi*64), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[8].conv[0][0] = nn.Conv2d(math.ceil(phi*64), math.ceil(phi*384), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[8].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*384), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[8].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[8].conv[1][0] = nn.Conv2d(math.ceil(phi*384), math.ceil(phi*384), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=math.ceil(phi*384), bias=False)\n",
        "  net_m.features[8].conv[1][1] = nn.BatchNorm2d(math.ceil(phi*384), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[8].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[8].conv[2] = nn.Conv2d(math.ceil(phi*384), math.ceil(phi*64), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[8].conv[3] = nn.BatchNorm2d(math.ceil(phi*64), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[9].conv[0][0] = nn.Conv2d(math.ceil(phi*64), math.ceil(phi*384), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[9].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*384), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[9].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[9].conv[1][0] = nn.Conv2d(math.ceil(phi*384), math.ceil(phi*384), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=math.ceil(phi*384), bias=False)\n",
        "  net_m.features[9].conv[1][1] = nn.BatchNorm2d(math.ceil(phi*384), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[9].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[9].conv[2] = nn.Conv2d(math.ceil(phi*384), math.ceil(phi*64), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[9].conv[3] = nn.BatchNorm2d(math.ceil(phi*64), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[10].conv[0][0] = nn.Conv2d(math.ceil(phi*64), math.ceil(phi*384), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[10].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*384), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[10].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[10].conv[1][0] = nn.Conv2d(math.ceil(phi*384), math.ceil(phi*384), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=math.ceil(phi*384), bias=False)\n",
        "  net_m.features[10].conv[1][1] = nn.BatchNorm2d(math.ceil(phi*384), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[10].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[10].conv[2] = nn.Conv2d(math.ceil(phi*384), math.ceil(phi*64), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[10].conv[3] = nn.BatchNorm2d(math.ceil(phi*64), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[11].conv[0][0] = nn.Conv2d(math.ceil(phi*64), math.ceil(phi*384), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[11].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*384), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[11].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[11].conv[1][0] = nn.Conv2d(math.ceil(phi*384), math.ceil(phi*384), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=math.ceil(phi*384), bias=False)\n",
        "  net_m.features[11].conv[1][1] = nn.BatchNorm2d(math.ceil(phi*384), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[11].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[11].conv[2] = nn.Conv2d(math.ceil(phi*384), math.ceil(phi*96), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[11].conv[3] = nn.BatchNorm2d(math.ceil(phi*96), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[12].conv[0][0] = nn.Conv2d(math.ceil(phi*96), math.ceil(phi*576), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[12].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*576), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[12].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[12].conv[1][0] = nn.Conv2d(math.ceil(phi*576), math.ceil(phi*576), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=math.ceil(phi*576), bias=False)\n",
        "  net_m.features[12].conv[1][1] = nn.BatchNorm2d(math.ceil(phi*576), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[12].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[12].conv[2] = nn.Conv2d(math.ceil(phi*576), math.ceil(phi*96), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[12].conv[3] = nn.BatchNorm2d(math.ceil(phi*96), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[13].conv[0][0] = nn.Conv2d(math.ceil(phi*96), math.ceil(phi*576), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[13].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*576), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[13].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[13].conv[1][0] = nn.Conv2d(math.ceil(phi*576), math.ceil(phi*576), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=math.ceil(phi*576), bias=False)\n",
        "  net_m.features[13].conv[1][1] = nn.BatchNorm2d(math.ceil(phi*576), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[13].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[13].conv[2] = nn.Conv2d(math.ceil(phi*576), math.ceil(phi*96), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[13].conv[3] = nn.BatchNorm2d(math.ceil(phi*96), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[14].conv[0][0] = nn.Conv2d(math.ceil(phi*96), math.ceil(phi*576), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[14].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*576), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[14].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[14].conv[1][0] = nn.Conv2d(math.ceil(phi*576), math.ceil(phi*576), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=math.ceil(phi*576), bias=False)\n",
        "  net_m.features[14].conv[1][1] = nn.BatchNorm2d(math.ceil(phi*576), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[14].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[14].conv[2] = nn.Conv2d(math.ceil(phi*576), math.ceil(phi*160), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[14].conv[3] = nn.BatchNorm2d(math.ceil(phi*160), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[15].conv[0][0] = nn.Conv2d(math.ceil(phi*160), math.ceil(phi*960), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[15].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*960), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[15].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[15].conv[1][0] = nn.Conv2d(math.ceil(phi*960), math.ceil(phi*960), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=math.ceil(phi*960), bias=False)\n",
        "  net_m.features[15].conv[1][1] = nn.BatchNorm2d(math.ceil(phi*960), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[15].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[15].conv[2] = nn.Conv2d(math.ceil(phi*960), math.ceil(phi*160), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[15].conv[3] = nn.BatchNorm2d(math.ceil(phi*160), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[16].conv[0][0] = nn.Conv2d(math.ceil(phi*160), math.ceil(phi*960), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[16].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*960), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[16].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[16].conv[1][0] = nn.Conv2d(math.ceil(phi*960), math.ceil(phi*960), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=math.ceil(phi*960), bias=False)\n",
        "  net_m.features[16].conv[1][1] = nn.BatchNorm2d(math.ceil(phi*960), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[16].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[16].conv[2] = nn.Conv2d(math.ceil(phi*960), math.ceil(phi*160), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[16].conv[3] = nn.BatchNorm2d(math.ceil(phi*160), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[17].conv[0][0] = nn.Conv2d(math.ceil(phi*160), math.ceil(phi*960), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[17].conv[0][1] = nn.BatchNorm2d(math.ceil(phi*960), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[17].conv[0][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[17].conv[1][0] = nn.Conv2d(math.ceil(phi*960), math.ceil(phi*960), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=math.ceil(phi*960), bias=False)\n",
        "  net_m.features[17].conv[1][1] = nn.BatchNorm2d(math.ceil(phi*960), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[17].conv[1][2] = nn.ReLU6(inplace=True)\n",
        "  net_m.features[17].conv[2] = nn.Conv2d(math.ceil(phi*960), math.ceil(phi*320), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[17].conv[3] = nn.BatchNorm2d(math.ceil(phi*320), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  net_m.features[18][0] = nn.Conv2d(math.ceil(phi*320), math.ceil(phi*1280), kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
        "  net_m.features[18][1] = nn.BatchNorm2d(math.ceil(phi*1280), eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  net_m.features[18][2] = nn.ReLU6(inplace=True)\n",
        "\n",
        "  temp_count_m = count_parameters(net_m)\n",
        "  y_val_mobilenet_width_scaling.append(temp_count_m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "qM-EyhI9VfK7",
        "outputId": "5d9f5100-e52f-4ae9-8c2e-0761bc5f6e0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4ff0013940>]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAEWCAYAAAB2c65HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5dn/8c9FEhIhQETCIgkEBUFwAYkL4laXqq1L61atG2prbdW2T1u72opLW2ufx99TpdXHuuBWt6ot4m61rSJaVkE2RVnCvpkNSMhy/f44JziEZDIJmUxm5vt+veaVOft1zkzmOvd97nMfc3dEREQk+XRJdAAiIiLSNkriIiIiSUpJXEREJEkpiYuIiCQpJXEREZEkpSQuIiKSpJTERdKAmbmZDW3veTsjM1tuZicnYLsnmdkvzaxHR29bAmZ2lZl9J9FxdKS0SuJm9jMze7nRuI+bGXdh+H7nD5qZTTSzGjOrCF8fmdkkMxsQTr/YzCrD13Yzq48Yrgzn2e0HxswmmNk7UeI+28zmmlm5mW0yszfNbEjE9APM7JlwWpmZzTOzH5hZRsQ8uWEcLzex/iZ/9MzsBDNbFTH8TzOrMrPCiHEnm9nyRstdaGbvm9lWM9sQvv+OmVkz+/fP8Dgf2mj88+H4EyLGjTSzKeF+VpjZW2Z2dMT0onCZhuO+3sz+ZGZZTe1vtGMfsb+VEa8XIo6Nm9mfGi3zjplNiFh3XaPlK81s30bD9eH3pWH44qbiSSdmdp+ZLQmPzYQO3G6bTgDM7FjgOeBLwPNm1rXR9BvM7MPwO7vMzG5op5Ajt3GUmb1uZlvMbGP4mzCgvbfTWYXH9Gbgh2Z2W6Np2Wb2gJmtCD+DuWZ2ehxiOMjMXg1/izukE5a0SuLAv4GjG5Jb+AXPAsY0Gjc0nLcpT7l7D6A38FWgPzDLzAa4++PunuvuucDpwJqG4XBcq1lwAvEI8EOgFzAE+CNQF07fH3gfKAEOdvdewPlAMRBZIjgXqAZOMbP+bYkltBX4ZZR4fwj8Afg9wbHpB1wDjAe6Nrcc8BFwWcR69gHGARsjxu0PTAPmExyHfYHngdfMbFyj9eWFx/zgcD3XxrZ7u7ku8jN09zMjpm0FLjWzoijLT2+0fK67N/5erATOjBj3eBtjTSUfAN8BZic6kJaY2SHA08BFwHFAGfComUX+vhrB93tv4DTgOgsLCu1ob+A+oAgYDFQAD7XzNjolM7sc+DbB8T8OONfMrouYJZPgN/J4gt/RG4GnW/jfbYsagu/CVe283malWxKfQZC0R4fDxwJvAUsajfvE3ddEW5G717j7AuBrBInmh3GJOIhrmbv/wwMV7v6su68Mp98MvOvuP3D3tWFsS9z96+5eGrGey4F7gXnAJXsQz13ARWFC3YWZ9QJuAb7j7n8NY3V3n+PuF7t7dZT1Pg58LaL24CKCBL0jYp6JBEnxF+6+JVz/XcCjwO+aWqm7bwBeB0a2cj9jUQpMBm6Kw7pbxcyOMLPpZlZqZmstqCFq8qTJzCab2b1hqa3CzP5lZoMbzXayBTVSpWb2x4ZaFDPb34KaoM1haeNxM8tr7/1x9z+6+z+Aqjau4nAzW2hmn5nZQ2aW0zDBzM4IS2KlZvZumIQxs0eBQcALYY3Ij8Pxz5jZOgtqf/5tZqMi1lUEPAtc4u4vuXsNwW9CLcHJbMP+3OHus9291t2XAH8nOLFtN+7+srs/4+7l7r4NmNSabZjZF8PajzILaq/+ZWbfCKdF/dzDGowbLKgF3BqWevuZ2cvhd+wNM9s7nLehtuwKMysJP6NrzOzwcPlSM5sUse6Wtv1l4CfA8e7+qbuvJkjW3zCz88Njs9XdJ7r7cnevd/epwDJg7J4c88bC394HgAXtud5o0iqJu/sOglLrceGo44C3gXcajWuuFN7UOusI/iGPbb9IdzEbGGFm/8/MvmBmjUv0JwN/jbaC8Af6BIJE+TgRJd42WA38meDkobFxQDbB8WitNcBC4Ivh8GUENRCRTgGeaWLZp4HxZrZX4wlmti9wKvBeG2KKxa8JzvqHx2n9saoD/gvoQ/A5nERQkm3OxcCt4fxzCb4Xkc4ADgcOAS4gOIYQlCh/S1ALciBQSHBy1aSIH+WmXn9qbrl2cHEY8/7AAQQlL8xsDPAg8C1gH+D/gClmlu3ul7Jrrcgd4bpeBoYBfQn+H3ceqzApDAtPOBrG1YYnrdc3FVh4QnQsUX7ooxyzUjP7aYzH4Lho22i0vT4EvyM/IzguS4CjI2eh5c/9XIL/0QOAMwmO28+BfIJc891G8x9JcFy/Bvwv8AuC37NRwAVmdnws23b3F919pLuXRIzb4O6j3b2p3wvMrF8YZ5PHx8yOaeEzOKap5RIhKZO4mT1owbXWD2OYd5AF103nmNk8gmTRkLCPJUjibzca969WhrSGoHo9Vn+L/EIAzf6YufunBAl4IEGy2hSWpBqS+T7A2ha2dykwz90XAk8Co8Ifs7b6LXBmZIkk1AfY5O61DSPCkk6pBdd8jyO6R4DLzGwEQXX49CbW39S+riX4Lkd+BpvCY7uaoNo76olOFHc1+ue9NXKiu68jqOG4pZnlj2q0/CdtjCMqd5/l7u+FCWQ5QXI6PsoiL7r7v8PakV8A4yyirQNwu7uXhjU+bxHWVLn7Und/3d2r3X0jcGe07bj7Ie6e18wrng2QJrl7ibtvITjRuigcfzXwf+7+vrvXufvDBJeZjoqyDw+GtT7VBMnjUAtqndpqIsH3tdmq7ijHLM/db29pA2Htwq+AWK+9fwlY4O7Phf+/dwHrIuKJ5XO/293XhyXht4H3w1q4KoJatca/Obe6e5W7v0bwP/pEmHwblh/Tim3HzIL2MY8DD7v74qbmcfd3WvgMmm3D1NGSMokTVGGeFuO8NwJPu/sY4EKCEsoxZtYbyHf3j4F3Ca6V9wYOohUl8dBAYEsr5v9K5BeC6CUmwh/nC9w9n+Ak4ziCH16AzUBLjVcuIyw9hP8g/yKoXm+T8B9pErsnrs1AHzPLjJj36HAfN9Py9+054ETgOoIq8sY20fS+DgDqgc8ixvUJt9uN4Dr6qy1suznfbfTP21R7gN8Bp1qjhnmh9xotv9tliPZgQePGqWG1bznwG4KTnuZElloqCb6/+0ZMXxfxfhuQG26nn5k9aWarw+081sJ2EqUk4v0KPt+3wQQNnyJPogvZdd93MrMMM7vdzD4J93d5OKlN+2zBddrLgC979MtLbWZBO5qXge+5+9sxLrYvu34nHIhs1BrL574+4v32JoYb1yLGNH97fucsaKfwKMFluutamD0pJGUSd/d/0yhphtdNXjGzWWb2dliaA3CgZ/i+F8E/YS/gmwQ/7rh7OUFp+psEjdGWxRpL+KU4k+DMMe7cfQZBsjsoHPUGQTVWkyxouT0M+Fn4A7+OoBrr65HJtg1+D3yBXa8pTSco1ZzdlhWG1/FeJmig0lQSf4Og0V5jFxBcK9/WxDq3E5z0HRVWGbY7d99MUB14a0vzxtE9wGJgmLv3JKjGbPJugFDkHQa5BLUYUduBhH5D8D91cLidS6Jtx8wW2O6t8xte98awvbaKrFUYxOf7VgL8utGJVTd3fyKc3rhF8dcJvs8nE/xuFIXjox3bJpnZlcBPgZPcfVUL8zZ3zCrN7OdRlhtM8H9yq7s39T/UnLVAQcR6LHKYVn7u7axdth3u0wMEjW3P9aD9QnPzHtvCZxCvy6etlpRJvBn3Ade7+1jgR3xeRT0RuMSCW6VeImilPBP4Absm3nfCcTGVws0s08wOBJ4gaIV9ZzvsQ1PbOcbMvmlmfcPhEcBZfH6N9yaCWoTfW9jq3MyGmtljFjT+uJzPG3aNDl8HAXsRtKBvkGVmORGvqAneg0Zz/wP8uNG4m4E/mdl5ZtbDzLqY2Wige4y7/HOCBirLm5h2c7ivvzaz3uH6ryco2fykqZWZWTbB5YR1BLUBzcy2y77nNDNfNHcSXEM8sA3LtoceQDlQGX5Hvt3C/F8Kv1tdCU4+3ou8ptjCdiqBMjMbSAvVte4+yndvnd/wuqa55cysa/g5GJ9/N7uE006wlm/fudbMCsLatV8AT4Xj/wxcY2ZHWqC7mX3ZPr+3ez2wX6P9rSb47nQjSCitZsFtg78BTvHgEllUUY5Zrrs3GUP4ebxJcClhtxMkC255XN7MJl8EDjazr4T/+9cS/K41aNXn3s7aa9v3EPx/nhme3DfL3d9u4TNostAWfqdyCO/ECb+32W2MNyYpkcTDksTRwDNmNpfgemBDtetFwGR3LyC47vMoQXVyX4LE3eDtcFxLSfxrFtzzXQZMIfjnHusttGbfA6UESXt+uN1XCK4v3QHg7p8QNGQqAhaYWRlBa9mZBLc7XEBwrWpdxGsZwXGIrFJ/iaAKq+E1MYbY/kB4q1sDDxoD/YAgua8PX/9HkGTfbWmFHtx+1eT1pvDSxzHAoQQ1KmsJaiFOdfdpjWYvDY/XeoLjc1ZYRdiUo9l137dHnMRManQGPquZ2MoJPpPGbSPGNXEWf3jzR6DNfkRQaqwgSFRPRZ+dvxCcAG4hqE2J9Y6Fm4HDCL7/LxLUCsXDawSfxdEEJ+jb+bzdSiEtf5f+Eq7jU+AT4DYAd59JUOM2ieDyy1JgQsRyvwVutKCq/UcE7TRWELStWEjbG0jeRtB+ZUYcayK+QXACMjHy+xYxvZCw9rExd99EUMt1B8Fv2kiC35CGKv+O+tybssfbDmsovkVQiFkXcXzau0+GwQTf1YYGc9sJGgnGjTX/u9a5WXBrx1R3P8jMegJL3H2366VmtgA4raGUYWafAkd5cOuRSNoxs8nAKne/MdGxtIWZ3Q884+5tbeeQlszsNYLr5ItimLcLwTXxi939rbgHJ22WEiXxsBS0zMJ7AsMqjYZGRisJGrMRVn/nENGBiIgkF3f/hhJ467n7F6MlcDM71czywurfhjYV8bo1U9pJUiZxM3uCoBHVcDNbZWZXEdwXepWZfUBQldHQuOqHwDfD8U8AE6JUq4oknAUdZDTVmMabGd9sQyeRVhhHcOlhE0Fj3a+0dO1YEi9pq9NFRETSXVKWxEVERCToFD6p9OnTx4uKihIdhoiISIeZNWvWprDDr10kXRIvKipi5syZiQ5DRESkw5jZiqbGqzpdREQkSSmJi4iIJCklcRERkSSlJC4iIpKklMRFRESSlJK4iIhIklISFxERSVJK4iIiIu3kk42V/M9rS9i2o7ZDtqckLiIi0k5unbqQydOWs21HXYdsT0lcRESkHby5eD3/XLKR7508jD652R2yTSVxERGRPVRdW8ctLyxkv/zuXDauqMO2qyQuIiKyhx6atpzlm7fxqzNG0jWz41KrkriIiMge2FBexd3/+JiTD+zLCcP7dui2lcRFRET2wO9eWUJNnXPjl0d2+LaVxEVERNpozsrPeHb2Kq48ZghFfbp3+PaVxEVERNqgvt6ZOGUBfXtkc92JQxMSg5K4iIhIGzw7exUfrCrjp6ePIDc7MyExKImLiIi0UkVVDb97ZQljBuXxldEDExZHYk4dREREktjdby5lU2U1D1xeTJculrA4VBIXERFphU83VvLQtGVcUFzAoYV5CY1FSVxERKQVbp26kJzMDG44dUSiQ1ESFxERidWbi9fz1pKNfPekYeT36Jj+0aNREhcREYnBjtp6bp26iP3yu3P50UWJDgdQEhcREYnJQ9OWsWzT1g7vHz2auEVhZoVm9paZLTSzBWb2vSbmOcHMysxsbvj6VbziERERaasN5VXc9Y+POWlEx/ePHk08bzGrBX7o7rPNrAcwy8xed/eFjeZ7293PiGMcIiIie+R3ryxhR109N57R8f2jRxO3kri7r3X32eH7CmARkLg74kVERNqgoX/0q47ZjyEJ6B89mg6p1DezImAM8H4Tk8eZ2Qdm9rKZjeqIeERERGJRX+9MfGFhQvtHjybuSdzMcoFnge+7e3mjybOBwe5+KHA38Ldm1nG1mc00s5kbN26Mb8AiIiKh5+as5oOSUn5yWuL6R48mrknczLIIEvjj7v5c4+nuXu7uleH7l4AsM+vTxHz3uXuxuxfn5+fHM2QREREg6B/99pcXM7owj6+O6ZxXg+PZOt2AB4BF7n5nM/P0D+fDzI4I49kcr5hERERiNSnsH/3ms0YltH/0aOJZNzAeuBSYb2Zzw3E/BwYBuPu9wHnAt82sFtgOXOjuHseYREREWvTpxkoenLaM88cmvn/0aOKWxN39HSDqqYu7TwImxSsGERGRtrh16kKyMzO44bThiQ4lqs7R5YyIiEgn8dbiDWH/6EPp2yMn0eFEpSQuIiISCvpHX8h+fboz4eghiQ6nRUriIiIiocnvLuPTTVv55Zmdp3/0aDp/hCIiIh1gQ0UVd/1jKSeO6MsXOlH/6NEoiYuIiAB3vLKE6to6ftnJ+kePRklcRETS3tySUv46axVXHjOk0/WPHo2SuIiIpLX6emfilAXk98jm+hOHJTqcVlESFxGRtPbcnNXM7cT9o0ejJC4iImmrsrqW370S9I9+TiftHz2a5DrlEBERaUd3v/kxGyuq+fNlxZ22f/RoVBIXEZG0tGzTVh58ZxnnjS1gdCfuHz0aJXEREUlLDf2j/7iT948ejZK4iIiknbeWbODNxRuSon/0aJTERUQkreyorefWF5Knf/RolMRFRCSt7Owf/Yzk6B89muSOXkREpBUa+kf/wvB8vjAiOfpHj0ZJXERE0sbvk7B/9GiUxEVEJC3MLSnlmVmruHL8EPbLz010OO1CSVxERFJeQ//ofXKzue7EoYkOp90oiYuISMp7fmf/6MPpkZOV6HDajZK4iIiktMrqWm5/ZTGHFuZx7mEFiQ6nXanvdBERSWmT3lzKxopq7rt0bFL2jx6NSuIiIpKylm3aygPvfMq5hxUwZtDeiQ6n3SmJi4hIyrpt6kK6ZnThJ0ncP3o0SuIiIpKS/rlkA/9YvIHvnjSMvj2Tt3/0aJTERUQk5eyoreeWqQsZ0qc7V4xP7v7Ro1ESFxGRlPPwu8v5dONWfnnGgUnfP3o0qbtnIiKSljZWVHPXPz7mC8PzOXFEv0SHE1dxS+JmVmhmb5nZQjNbYGbfa2IeM7O7zGypmc0zs8PiFY+IiKSH37+6mKoU6h89mniWxGuBH7r7SOAo4Foza3xETweGha+rgXviGI+IiKS4D0pKeXrmKq5Iof7Ro4lbEnf3te4+O3xfASwCBjaa7WzgEQ+8B+SZ2YB4xSQiIqmrvt6Z+ELQP/r1KdQ/ejQdck3czIqAMcD7jSYNBEoihlexe6LHzK42s5lmNnPjxo3xClNERJLY3+auZs7K1OsfPZq4J3EzywWeBb7v7uVtWYe73+fuxe5enJ+f374BiohI0qusruX2l1Ozf/Ro4prEzSyLIIE/7u7PNTHLaqAwYrggHCciIhKzSW8uZUNFNRPPHJly/aNHE8/W6QY8ACxy9zubmW0KcFnYSv0ooMzd18YrJhERST3LN23lwXeWcc5hA1Oyf/Ro4vkUs/HApcB8M5sbjvs5MAjA3e8FXgK+BCwFtgFXxDEeERFJQbe9uJCsDOOnp41IdCgdLm5J3N3fAaLWabi7A9fGKwYREUlt/1yygTcWbeCnp49I2f7Ro1GPbSIikpQa+kcv2qcbV4wvSnQ4CaEkLiIiSemR6Q39o48kOzMj0eEkhJK4iIgknY0V1fzhjY85YXg+J47om+hwEkZJXEREks5/v7qE7TVB/+jBzVDpSUlcRESSyrxVpTw9q4Qrxhexfxr0jx6NkriIiCQNd2filAXs070r1580LNHhJJySuIiIJI2/zV3N7JWl/Pi0EfRMk/7Ro1ESFxGRpFBZXctvX1rMoQW9OC+N+kePRklcRESSwh/fCvpHv+msUWnVP3o0SuIiItLpLd+0lQfeDvpHPyzN+kePRklcREQ6vdteXJS2/aNH0+okbmZ7m9kh8QhGRESksX99tJE3Fq3nuhOHpWX/6NHElMTN7J9m1tPMegOzgT+bWXOPFxUREWkXNXX13PLCAor26caVxxQlOpxOJ9aSeC93LwfOAR5x9yOBk+MXloiICDz87nI+SfP+0aOJNYlnmtkA4AJgahzjERERAWBTZdA/+vEHpHf/6NHEmsRvBl4Flrr7DDPbD/g4fmGJiEi6+/0r6h+9JZktzWBmGUChu+9szObunwLnxjMwERFJX/NXlfH0rBKuGj+EoX3Tu3/0aFosibt7HXBRB8QiIiIS9I/+QtA/+ndPVv/o0bRYEg9NM7NJwFPA1oaR7j47LlGJiEja+vvcNcxa8Rl3nHuI+kdvQaxJfHT495aIcQ6c2L7hiIhIOttaXctvX17EIQW9OG+s+kdvSUxJ3N2/EO9ARERE/vjWUtaXV/Oni8eqf/QYxNrZSz8ze8DMXg6HR5rZVfENTURE0smKzVu5/+1lnDNmIGMHq3/0WMR6i9lkglvM9g2HPwK+H4+AREQkPd06dRGZGcZPTlf/6LGKNYn3cfengXoAd68F6uIWlYiIpJV/7+wffSj91D96zGJN4lvNbB+CxmyY2VFAWdyiEhGRtFFTV88tUxcyeJ9uXHXMkESHk1RibZ3+A2AKsL+ZTQPygfPjFpWIiKSNR6avYOmGSu6/rFj9o7dSrEl8AXA8MBwwYAl6FrmIiOyhTZXV/O/rH3HcAfmcdKD6R2+tWBPxdHevdfcF7v6hu9cA06MtYGYPmtkGM/uwmeknmFmZmc0NX79qbfAiIpLc/vvVoH/0X6l/9DaJWhI3s/7AQGAvMxtDUAoH6Al0a2Hdk4FJwCNR5nnb3c+ILVQREUkl81eV8dRM9Y++J1qqTj8VmAAUAHdGjC8Hfh5tQXf/t5kV7UFsIiKSotQ/evuImsTd/WHgYTM7192fjcP2x5nZB8Aa4EfuvqCpmczsauBqgEGDBsUhDBER6UgN/aP/7tyD1T/6Hoj1mvi0OPTYNhsY7O6HAncDf2tuRne/z92L3b04Pz9/DzcrIiKJ1NA/+sEDe3H+2MJEh5PUYk3iD9HOPba5e7m7V4bvXwKyzKzPnqxTREQ6vz/9M+gffeJZI9U/+h5KWI9tZtbfwqaIZnZEGMvmPVmniIh0bis2b+XP/17GV8cMZOzg3okOJ+nFep94q3tsM7MngBOAPma2CrgJyAJw93uB84Bvm1ktsB240N29LTshIiLJ4bYXg/7Rf6r+0dvFnvTYdl60Bdz9ohamTyK4BU1ERNLA2x9v5PWF67nh1OHqH72dxPo88dlmtkuPbWGHLyIiIi2qqavn5hfUP3p7iymJm1kG8CWgKFzmi2aGu98ZdUEREUl7NXX13Pj8hyzdUMmfLysmJ0v9o7eXWKvTXwCqgPmEjdtERERaUl5Vw7WPz+btjzdx3ReGcrL6R29XsSbxAnc/JK6RiIhISln12TaunDyDTzdu5Y5zD+GCw3VPeHuLNYm/bGZfdPfX4hqNiIikhA9KSrnq4ZlU19bx8JVHMH6ougGJh1iT+HvA82bWBaghaNzm7t4zbpGJiEhSeuXDdXz/qTn0yc3miW8eybB+PRIdUsqKNYnfCYwD5utebhERaYq7c//by/jNy4s4tCCPP19WTH6P7ESHldJiTeIlwIdK4CIi0pTaunomvrCAx95byZcO7s+dF4xWK/QOEGsS/xT4Z/gAlOqGkbrFTEREKqpquO4vc/jXRxu55vj9+fGpw9UnegeJNYkvC19dw5eIiAhrSrdz5eQZfLyhkt+eczAXHaHHRXekWHtsuznegYiISHL5cHUZV06ewfYddUy+4nCOHaZHRXe0WHtsywd+DIwCdnZ46+4nxikuERHpxN5YuJ7rn5hD7+5defTbRzK8v1qgJ0KsjyJ9HFgMDAFuBpYDM+IUk4iIdGIPTVvGNx+dybB+uTx/7dFK4AkU6zXxfdz9ATP7nrv/C/iXmSmJi4ikkdq6em6dupCHp6/g1FH9+N+vjWGvrmqBnkixJvGGJ5atNbMvA2sAPc1dRCRNbK2u5fon5vDm4g1889gh/PT0A8lQC/SEizWJ32ZmvYAfAncDPYH/iltUIiLSaawrq+LKyTNYsr6C275yEJccNTjRIUmoxSQePoZ0mLtPBcqAL8Q9KhER6RQWrCnjqskzqayu5YHLizlhuJ5C1pm02LDN3euAizogFhER6UTeXLye8++djhk8c804JfBOKNbq9GlmNgl4CtjaMNLdZ8clKhERSahHpi9n4pQFjNy3Jw9cfjj9eua0uIx0vFiT+Ojw7y0R4xzQfeIiIimkrt759YuLeHDaMk4+sB93XTSabl1jTRXS0WLtsU3XwUVEUty2HbV894m5vLFoPVeOH8IvvqwW6J1dzKdX4a1ljXtsu6X5JUREJFmsL6/iqodnsHBNOTefNYrLjy5KdEgSg1i7Xb0X6EbQMv1+4DzgP3GMS0REOsiiteVcNXkGpdtruP/yYk4c0S/RIUmMYu129Wh3vwz4LHwYyjjggPiFJSIiHeGfSzZw/r3TqXPnmWvGKYEnmVir07eHf7eZ2b7AZmBAfEISEZGO8Nh7K7hpygKG9+vBAxOKGdBrr0SHJK0UaxKfamZ5wB3ArHDc/fEJSURE4qm+3vnty4v489vLOHFEX+66aAy52WqBnoxi/dT+G/g2cCwwHXgbuCdeQYmISHxs31HH95+aw6sL1nP5uMH88oyRZGbEemVVOptYP7mHCVqm30XQd/pI4JFoC5jZg2a2wcw+bGa6mdldZrbUzOaZ2WGtCVxERFpnQ0UVF943ndcWruemM0dy89kHKYEnuVhL4ge5+8iI4bfMbGELy0wGJtF8sj8dGBa+jiQo2R8ZYzwiItIKS9ZVcOXkGWzZuoP7Li3mlJFqwJYKYj0Fm21mRzUMmNmRwMxoC7j7v4EtUWY5G3jEA+8BeWamxnIiIu3s7Y83ct4971JTV8/T3xqnBJ5CYi2JjwXeNbOV4fAgYImZzQfc3Q9pw7YHAiURw6vCcWsbz2hmVwNXAwwaNKgNmxIRSU9P/GclN/7tQ4b1zeXBCYezb55aoKeSWJP4aXGNogXufh9wH0BxcbEnMhYRkWRQX+/c8eoS7v3XJxx/QD6Tvj6GHlmdxAsAABPMSURBVDlZiQ5L2lmsfaeviMO2VwOFEcMF4TgREdkDVTV1/ODpubw0fx0XHzmIm88apQZsKSqRNwZOAa4zsycJGrSVuftuVekiIhK7TZXVfOPhmXywqpQbv3wgVx0zBDM9xCRVxS2Jm9kTwAlAHzNbBdwEZAG4+73AS8CXgKXANuCKeMUiIpIOPl5fwRWTZ7Cpspp7Lh7LaQf1T3RIEmdxS+LuflEL0x24Nl7bFxFJJ9OWbuKax2aRnZnBU1eP49DCvESHJB1A/eyJiCS5p2eU8PPn57NffncenHA4BXt3S3RI0kGUxEVEklR9vfM/ry/hj299wrHD+vDHiw+jp1qgpxUlcRGRJFRVU8ePnvmAqfPWctERhdxy9kFkqQV62lESFxFJMpsrq7n60VnMWvEZPzt9BFcft59aoKcpJXERkSTyycZKrnhoBuvLq/jTxYfxpYPVW3U6UxIXEUkS0z/ZzDWPzSIrw3jy6qMYM2jvRIckCaYkLiKSBJ6dtYqfPjePwft056EJh1PYWy3QRUlcRKRTc3f+3xsfc9c/Pubo/ffhnkvG0msvtUCXgJK4iEgnVV1bx4//Oo+/z13DBcUF3PaVg+maqRbo8jklcRGRTmjL1h1869GZzFj+GTecOpzvnLC/WqDLbpTERUQ6mWWbtnLFQ/9hTVkVd180hjMP3TfRIUknpSQuItKJ/GfZFq5+dCZdzHjim0cydnDvRIcknZiSuIhIJ/H3uau54Zl5FPTei4cmHM7gfbonOiTp5JTERUQSzN25+82l3Pn6Rxy1X2/+75JienVTC3RpmZK4iEgCbd9Rxy/+Np/nZq/m3MMK+O05aoEusVMSFxFJgJIt23jsvRU8OaOEsu01/PCUA7juxKFqgS6toiQuItJB3J33Pt3C5HeX8frC9ZgZp43qz5XHFKkBm7SJkriISJxt31HH3+euZvK7y1m8roK9u2VxzfH7c8lRg9k3b69EhydJTElcRCROVpdu59HpK3hyxkpKt9Vw4ICe3HHuIZw1el9ysjISHZ6kACVxEZF25O78Z9kWHp6+nFcXrMfdOXVUfyYcXcQRQ3rrmre0KyVxEZF2UFVTx5S5a3jo3eUsWltOXrcsvnnsflxy1CAK9tYTxyQ+lMRFRPbA2rKgyvyJ/6zks201DO/Xg9vPOZizRw9kr66qMpf4UhIXEWkld2fWis946N3lvPLhOtydU0b2Y8LRQzhqP1WZS8dREhcRiVFVTR1T561l8rvL+HB1OT1zMrnqmCFcetRgCnurylw6npK4iEgL1pVV8fj7K/jL+yvZvHUHw/rm8uuvHsRXxwykW1f9jEri6NsnItIEd2f2ylImv7ucl+evpc6dk0b044rxRRy9/z6qMpdOQUlcRCRCdW0dL85by+R3lzNvVRk9cjKZcHQRl40rYtA+qjKXziWuSdzMTgP+AGQA97v77Y2mTwB+D6wOR01y9/vjGZOISFM2lFfx2Psr+cv7K9hUuYP987tz61cO4pwxA+merfKOdE5x+2aaWQbwR+AUYBUww8ymuPvCRrM+5e7XxSsOEZFo5qz8jMnvLuel+WuprXdOHN6XCeOLOGZoH1WZS6cXz9PLI4Cl7v4pgJk9CZwNNE7iIiIdakdtPS9/uJYHpy3ng5JSemRnculRRVw2bjBFfbonOjyRmMUziQ8ESiKGVwFHNjHfuWZ2HPAR8F/uXtJ4BjO7GrgaYNCgQXEIVUTSwcaKav7y/koee38FGyuq2a9Pd245exTnHFZArqrMJQkl+lv7AvCEu1eb2beAh4ETG8/k7vcB9wEUFxd7x4YoIsnug5JSHn53OS/MW0NNnXPC8HyuGD+EY4f2oUsXVZlL8opnEl8NFEYMF/B5AzYA3H1zxOD9wB1xjEdE0khNXT0vf7iOydOWMXtlKd27ZnDxkYO5bNxg9svPTXR4Iu0inkl8BjDMzIYQJO8Lga9HzmBmA9x9bTh4FrAojvGISBrYVFnNE2GV+fryaor26cZNZ47kvLEF9MjJSnR4Iu0qbknc3WvN7DrgVYJbzB509wVmdgsw092nAN81s7OAWmALMCFe8YhIavtwdRkPTVvOCx+sYUddPccdkM/t5xRx/AH5qjKXlGXuyXWJubi42GfOnJnoMESkE6ipq+fVBeuYPG05M1d8RreuGZw3toDLxhUxtK+qzCV1mNksdy9uPD7RDdtERFptc2U1T84o4dHpK1hXXsWg3t345RkjOb+4gJ6qMpc0oiQuIkljwZoyJk9bzt8/WMOO2nqOHdaHX3/1IE4Y3pcMVZlLGlISF5FOrbauntcWrmfytOX8Z/kW9srK4ILiAi4fV8Swfj0SHZ5IQimJi0inU1fvfLS+greWbOCx6StYU1ZFwd57ceOXD+T8sYX06qYqcxFQEheRTmB9eRVzVpYyt6SUuSWfMW9VGdt21AFw9P77MPGsUZx0YD9VmYs0oiQuIh1q+446PlxTxpyVnwVJe2Upa8qqAMjKMEYO6Mn5YwsYPSiPsYN66/GfIlEoiYtI3NTXO59u2srcktKdSXvxugrq6oNbWwt778XYot5cVZjH6MI8Ru3bk5ysjARHLZI8lMRFpN1s2bqDuSWfMXdlKXNKgurxiqpaAHpkZ3JoYR7fPn5/RhfmMXpQHn1ysxMcsUhyUxIXkTaprq1j4Zry8Dp2KXNWlrJyyzYAuhgM79+TMw/dl9GFeYwpzGP//Fz1nCbSzpTERaRF7s7KLdt2Jus5JaUsWlPOjrp6APr3zGF0YR4XHzmI0YV5HFzQi25d9fMiEm/6LxOR3ZRtr+GDktKdpey5JaVs2boDgL2yMji4oBdXjC9izKA8RhfuTf9eOQmOWCQ9KYmLpLnaunoWr6sIrmGvDG7x+mTjVgDMYGh+LieN6MvoQXmMKdybA/rlkpnRJcFRiwgoiYukFXdnbVnVLq3F568uo6omqBbvk9uV0YV5fHXMQMYM2puDC3qpL3KRTkxJXCSFba2uZd6qsl2S9oaKagC6ZnbhoH178vUjBoel7DwK9t4LMzU+E0kWSuIiKaKu3lm6oTK4xStsgPbR+grCW7Ip2qcb44f2CW7vKszjwAE96ZqpanGRZKYkLpKkNlRUhdewg9e8VWVUVgf3ZPfaK4vRhXmcOqo/owflMbogj727d01wxCLS3pTERTqhunpnc2U1a8uqWFdexbqyKtaWVbG+vIq1Zdsp2bKd1aXbAcjsYhw4oCfnHDZwZyl7SJ/uqhYXSQNK4iIdbEdtPevLg+S8tqyK9WGCXle+nXVlQcLeUFFNbUM9eCgrw+jXM4cBvXIoLtqbKwYGt3iN2reXuioVSVNK4iLtaGt1bUSJuYp1Zdt3K0lvqtyx23LdumYwoFcO/XvlMG7/PvTvlU3/XnsxoGcwrn+vHHp366oez0RkF0riIjFwd0q31USUmKtZV7Z9l+rudeVVO/sJj7R3tyz699qL/j2zOaQgL0jWYXIe0CuHfr1y6JGdqepvEWk1JXFJe3X1zsaKataWbf+8BN2o9LyurIrq2vpdlutikN8jKDHvn5/L+KF9Pk/MPT//q6puEYkXJXFJaVU1dWwoDxL07g3EguGNldU7H43ZoGtGl6Aau2cOhxbkceqo4H1DyXlArxzyc7PVc5mIJJSSuHR67s72mjoqq2qpqK6lsqqWyupaKqpq2VodvG8YLttes7PkvK68amd/35FyszN3JuhjhvXZpeTcML53966q3haRTk9JXOKmrt53Jtgg8dZQESbgrWHSrYxMyhHvP0/UNVRW19KooNykrpld6JmTSd8eQUIePShvl4ZhDcm6h7oRFZEUoSQuu6murdultBuZVHdNyg3Ta3aOi0zE23bUxbS97l0z6J6dSW5OJj3Cv31yu5GbnUWPnExyw3G52ZmfD++cP4vcnEy6Z2eQnalrzyKSXpTEk0htXT076urZURu8qmt3HY42rbq2Lij9NirtVjRO0FW1O58RHU0XI0yqWTsTal63rhT07hYk4t0Sb9buiTgnk+5dM8nQbVMiIm2iJN4Md989SUYMVzeROHfU1TWfYBsn1SjTdt1G3c7hWKqUW9I1s8vO0m5DiXbfvJyIpJvVRGk3Yv6w9JuT1UXXjEVEEiyuSdzMTgP+AGQA97v77Y2mZwOPAGOBzcDX3H15PGOKNGvFZ/zk2Xk7S6qRSbSmrh0yZiizi9E1s0vwyuiyy/vs8H1OVnA9N5iWsXO+7GaWa3if3eK0jJ3vu2dn6oEXIiIpJG5J3MwygD8CpwCrgBlmNsXdF0bMdhXwmbsPNbMLgd8BX4tXTI3lZmdyQL/cRkkwI6YE2TWzC9mNhndNoBlkZ3YhK6OLqotFRCQu4lkSPwJY6u6fApjZk8DZQGQSPxuYGL7/KzDJzMzd268YHMXw/j3408VjO2JTIiIi7S6edasDgZKI4VXhuCbncfdaoAzYp/GKzOxqM5tpZjM3btwYp3BFRESSS1JcIHX3+9y92N2L8/PzEx2OiIhIpxDPJL4aKIwYLgjHNTmPmWUCvQgauImIiEgL4pnEZwDDzGyImXUFLgSmNJpnCnB5+P484M2Ouh4uIiKS7OLWsM3da83sOuBVglvMHnT3BWZ2CzDT3acADwCPmtlSYAtBohcREZEYxPU+cXd/CXip0bhfRbyvAs6PZwwiIiKpKikatomIiMjulMRFRESSlCVbOzIz2wisaMdV9gE2teP6OivtZ2rRfqYW7Wdqicd+Dnb33e6xTrok3t7MbKa7Fyc6jnjTfqYW7Wdq0X6mlo7cT1Wni4iIJCklcRERkSSlJA73JTqADqL9TC3az9Si/UwtHbafaX9NXEREJFmpJC4iIpKklMRFRESSVFoncTM7zcyWmNlSM/tpouOJBzN70Mw2mNmHiY4lnsys0MzeMrOFZrbAzL6X6JjiwcxyzOw/ZvZBuJ83JzqmeDKzDDObY2ZTEx1LvJjZcjObb2ZzzWxmouOJFzPLM7O/mtliM1tkZuMSHVN7M7Ph4efY8Co3s+/HdZvpek3czDKAj4BTgFUET127yN0XJjSwdmZmxwGVwCPuflCi44kXMxsADHD32WbWA5gFfCUFP08Durt7pZllAe8A33P39xIcWlyY2Q+AYqCnu5+R6HjiwcyWA8XuntKdoJjZw8Db7n5/+GTLbu5emui44iXMMauBI929PTso20U6l8SPAJa6+6fuvgN4Ejg7wTG1O3f/N8ET4lKau69199nh+wpgETAwsVG1Pw9UhoNZ4Sslz8TNrAD4MnB/omORPWNmvYDjCJ5cibvvSOUEHjoJ+CSeCRzSO4kPBEoihleRgj/66cjMioAxwPuJjSQ+wirmucAG4HV3T8n9BP4X+DFQn+hA4syB18xslpldnehg4mQIsBF4KLw8cr+ZdU90UHF2IfBEvDeSzklcUpCZ5QLPAt939/JExxMP7l7n7qOBAuAIM0u5yyRmdgawwd1nJTqWDnCMux8GnA5cG14CSzWZwGHAPe4+BtgKpGQ7JIDwcsFZwDPx3lY6J/HVQGHEcEE4TpJUeI34WeBxd38u0fHEW1gd+RZwWqJjiYPxwFnh9eIngRPN7LHEhhQf7r46/LsBeJ7gUl+qWQWsiqg1+itBUk9VpwOz3X19vDeUzkl8BjDMzIaEZ00XAlMSHJO0Udjg6wFgkbvfmeh44sXM8s0sL3y/F0HDzMWJjar9ufvP3L3A3YsI/jffdPdLEhxWuzOz7mFDTMLq5S8CKXcnibuvA0rMbHg46iQgpRqdNnIRHVCVDkEVR1py91ozuw54FcgAHnT3BQkOq92Z2RPACUAfM1sF3OTuDyQ2qrgYD1wKzA+vFwP83N1fSmBM8TAAeDhs+doFeNrdU/b2qzTQD3g+OAclE/iLu7+S2JDi5nrg8bDQ9ClwRYLjiYvwZOwU4Fsdsr10vcVMREQk2aVzdbqIiEhSUxIXERFJUkriIiIiSUpJXEREJEkpiYuIiCQpJXGRFBc+JatPE+PPao+n95nZBDObtKfrEZHWS9v7xEXSnbtPQR0ciSQ1lcRFUoCZFYXPaX48fFbzX82sW8Qs15vZ7PC51SPCZXYrQZtZl7Dknhcx7mMz62dmZ5rZ++EDLN4ws35NxDHZzM6LGK6MeH+Dmc0ws3kNz0EPeyx7MXw++odm9rV2PCwiKU9JXCR1DAf+5O4HAuXAdyKmbQofsnEP8KPmVuDu9cDfga8CmNmRwIqwD+h3gKPCB1g8SfCEsZiY2ReBYQT9go8GxoYP+jgNWOPuh4bPu0/V3spE4kJJXCR1lLj7tPD9Y8AxEdMaHggzCyhqYT1PAQ0l4gvDYQgeEvSqmc0HbgBGtSK2L4avOcBsYARBUp8PnGJmvzOzY929rBXrFEl7SuIiqaNxH8qRw9Xh3zpabgszHRhqZvnAV/j8BOBuYJK7H0zQL3ROE8vWEv6umFkXoGs43oDfuvvo8DXU3R9w948InmY1H7jNzH7V0k6KyOeUxEVSxyAzGxe+/zpB9XerefBAheeBOwmeCrc5nNSLzx/Xe3kziy8HxobvzwKywvevAleGz3vHzAaaWV8z2xfY5u6PAb8ntR9PKdLu1DpdJHUsAa41swcJHvN4zx6s6ymCx/VOiBg3EXjGzD4D3gSGNLHcn4G/m9kHBNe3twK4+2tmdiAwPXxiVyVwCTAU+L2Z1QM1wLf3IGaRtKOnmImkADMrAqaGjcNEJE2oOl1ERCRJqSQuIiKSpFQSFxERSVJK4iIiIklKSVxERCRJKYmLiIgkKSVxERGRJPX/AYG2tXV1tlW+AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize = (8,4)) #plotting results in a graph\n",
        "plt.title(\"WIDTH SCALING MOBILENET__alpha = 1, beta^2 = 2, gamma^2 = 1\")\n",
        "plt.xlabel(\"phi values\")\n",
        "plt.ylabel(\"parameters\")\n",
        "plt.plot(x_val_mobilenet_width_scaling, y_val_mobilenet_width_scaling)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "6b38c7e00c8881d147c46cfeeb1130d51b3e6d426a5b7c3e5efcbeb3e798e816"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
